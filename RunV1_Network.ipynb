{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ola-sammy/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from six.moves import xrange  \n",
    "import tensorflow as tf\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as scipy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from src.parser import gen_parser\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "parser = gen_parser()\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting Up Savings and Files IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working dir: /home/ola-sammy/Documents/Imbizo2019/Project/V1_predictor_Sammy\n",
      "manual save dir: /home/ola-sammy/Documents/Imbizo2019/Project/V1_predictor_Sammy/manualsave\n"
     ]
    }
   ],
   "source": [
    "IDtag = str(int(time.time())) # use a unix time ID for each training\n",
    "working_dir = os.getcwd()\n",
    "print(\"Working dir: \" + working_dir)\n",
    "#mansave_dir = '/home/ola-sammy/Documents/Imbizo2019/Project/V1_predictor_Sammy/manualsave'\n",
    "mansave_dir = working_dir + '/manualsave' # the directory to save to\n",
    "print(\"manual save dir: \" + mansave_dir)\n",
    "savedirname = mansave_dir + '/training_manualsave_' + IDtag #filename for saving training\n",
    "savenetworkname = mansave_dir + '/network_manualsave_' + IDtag # saving network parameters\n",
    "savefigname = mansave_dir + '/training_plot_' + IDtag # saving training figure\n",
    "neuronbessavedirt = mansave_dir + '/neuronloss_' + IDtag # not used \n",
    "pearsonsavedir = mansave_dir + '/personplot' + IDtag # saving performance figure \n",
    "pearsonsavedatadir = mansave_dir + '/persondata' + IDtag # saving performance data \n",
    "losssavedir = mansave_dir + '/lossplot' + IDtag # not used\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a Folder to Save to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (tf.gfile.Exists(mansave_dir) == 0):\n",
    "    tf.gfile.MakeDirs(mansave_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the already Built Network: build_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import src.build_network as build_network\n",
    "from src.build_network import simpleRNN, ConvNetDrop, RConvNet, LnonL\n",
    "from src.utils import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of data to be fed into the Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading 1 file(s)\n",
      "/home/ola-sammy/Documents/Imbizo2019/Project/V1_predictor_Sammy/data/02_process.mat\n",
      "['/home/ola-sammy/Documents/Imbizo2019/Project/V1_predictor_Sammy/data/02_process.mat ncells:']\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "data_dir = FLAGS.data_dir\n",
    "fileindex = FLAGS.fileindex\n",
    "#Note: Files (Data)  must be in the same directory.\n",
    "filearray = [\n",
    "        '01_process.mat',\n",
    "        '02_process.mat',\n",
    "        '03_process.mat',\n",
    "        '04_process.mat',\n",
    "        '05_process.mat',\n",
    "        '06_process.mat',\n",
    "        '07_process.mat',\n",
    "        '08_process.mat',\n",
    "        '09_process.mat',\n",
    "        '10_process.mat']\n",
    "\n",
    "filename = filearray[fileindex]\n",
    "filepath = os.path.join(data_dir,filename)\n",
    "\n",
    "data = DataLoader([filepath],FLAGS) # loads and formats all the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of cells is 37\n",
      "y eval shape\n",
      "(52, 37)\n",
      "eval var is:\n",
      "0.1966469344714537\n"
     ]
    }
   ],
   "source": [
    "print(\"total number of cells is %d\" % (data.numcell))\n",
    "print(\"y eval shape\")\n",
    "print(np.shape(data.yeval))\n",
    "evalvar = np.var(data.yeval,axis = 0)\n",
    "print(\"eval var is:\") \n",
    "print(np.mean(evalvar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trials 270\n",
      "number of  pixels are 33 X 33\n"
     ]
    }
   ],
   "source": [
    "numtrain = data.numtrain\n",
    "numearlystop = data.numearlystop\n",
    "numeval =  data.numeval \n",
    "numbatch = np.minimum(numtrain,FLAGS.batch_size)\n",
    "numtrials = data.numtrials\n",
    "numpixx = data.numpixx  \n",
    "numpixy = data.numpixy\n",
    "print('number of trials %d' % (numtrials))\n",
    "print('number of  pixels are %d X %d' % (numpixx,numpixy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_training(lossbaseline, lossbaselineneuron, model = None, dataset = None):\n",
    "    if dataset is not None:\n",
    "        data = dataset\n",
    "\n",
    "    #start the training\n",
    "    with tf.Graph().as_default():\n",
    "    # generate placeholders\n",
    "        images_placeholder = tf.placeholder(tf.float32, shape = (None, data.numpixx, data.numpixy, 1))\n",
    "        activity_placeholder = tf.placeholder(tf.float32, shape = (None,data.numcell))\n",
    "        keep_prob_placeholder = tf.placeholder(tf.float32)\n",
    "        baselineloss_placeholder = tf.placeholder(tf.float32, shape=(data.numcell))\n",
    "\n",
    "        # network hyper-parameters as arrays\n",
    "        #2 conv layers\n",
    "        if FLAGS.numconvlayer == 1:\n",
    "            num_filter_list = [FLAGS.conv1] \n",
    "            filter_size_list = [FLAGS.conv1size] \n",
    "            pool_stride_list = [FLAGS.nstride1] \n",
    "            pool_k_list =[FLAGS.nk1]\n",
    "        elif FLAGS.numconvlayer == 2:\n",
    "            num_filter_list = [FLAGS.conv1, FLAGS.conv2] # [16,32]\n",
    "            filter_size_list = [FLAGS.conv1size, FLAGS.conv2size] # [7,7]\n",
    "            pool_stride_list = [FLAGS.nstride1, FLAGS.nstride2] # [2,2]\n",
    "            pool_k_list =[FLAGS.nk1, FLAGS.nk2 ]  # [3, 3]\n",
    "        elif FLAGS.numconvlayer == 3:\n",
    "            num_filter_list = [FLAGS.conv1, FLAGS.conv2, FLAGS.conv2] # [16,32]\n",
    "            filter_size_list = [FLAGS.conv1size, FLAGS.conv2size, FLAGS.conv2size] # [7,7]\n",
    "            pool_stride_list = [FLAGS.nstride1, FLAGS.nstride2, FLAGS.nstride2] # [2,2]\n",
    "            pool_k_list =[FLAGS.nk1, FLAGS.nk2, FLAGS.nk2]  # [3, 3]\n",
    "\n",
    "        #1 all-to-all hidden layer\n",
    "        dense_list = [FLAGS.hidden1] # [300]\n",
    "        keep_prob = FLAGS.dropout # 0.55\n",
    "        numcell = data.numcell\n",
    "\n",
    "        # if no model passed, use default\n",
    "        if model is None:\n",
    "\n",
    "            model = ConvNetDrop(images_placeholder, \n",
    "                num_filter_list, filter_size_list, pool_stride_list, \n",
    "                pool_k_list, dense_list, keep_prob_placeholder,numcell)\n",
    "\n",
    "        else:\n",
    "            model(images_placeholder)\n",
    "\n",
    "        print(\"model shape is\")\n",
    "        print(model.output.get_shape())\n",
    "\n",
    "        ## Add to the Graph the Ops for loss calculation.\n",
    "        loss = build_network.loss(model.output, activity_placeholder)\n",
    "        loss_per_neuron = build_network.losspercell(model.output, activity_placeholder)\n",
    "        train_op = build_network.training(loss, FLAGS.learning_rate)\n",
    "\n",
    "        # Add the variable initializer Op.\n",
    "        init = tf.global_variables_initializer()\n",
    "\n",
    "        # Create a session for running Ops on the Graph.\n",
    "        sess = tf.Session()\n",
    "        # Run the Op to initializactivitytraine the variables.\n",
    "        sess.run(init)\n",
    "\n",
    "        # setting up recording training progress\n",
    "        steplist = []\n",
    "        evallist = []\n",
    "        trainlist = []\n",
    "        earlystoplist = []\n",
    "        rmeanlist = []\n",
    "        rcelllist = []\n",
    "    \n",
    "        ## Start the training loop.\n",
    "        lossearlystopmin = 10e6 # large dummy value use for finding the minimum loss in the early stop data\n",
    "        for step in xrange(FLAGS.max_steps):\n",
    "            start_time = time.time()\n",
    "            batchindex = np.random.permutation(numtrain)[0:numbatch]\n",
    "            xtrainbatch = data.xtrain[batchindex ,:,:,:]\n",
    "            ytrainbatch = data.ytrain[batchindex ,:]\n",
    "      \n",
    "            feed_dict = {\n",
    "                images_placeholder: xtrainbatch,\n",
    "                activity_placeholder: ytrainbatch,\n",
    "                keep_prob_placeholder: keep_prob\n",
    "                }\n",
    "\n",
    "            _, loss_value = sess.run([train_op, loss],\n",
    "                               feed_dict=feed_dict)\n",
    "\n",
    "            FVE = 1 - loss_value / lossbaseline\n",
    "            duration = time.time() - start_time\n",
    "            # print progress.\n",
    "            if step % 50 == 0:\n",
    "                ## Print status\n",
    "\n",
    "                print('Step %d: loss = %.4f; FVE = %5.2f (%.3f sec)' % (step, loss_value, FVE, duration))\n",
    "                  ## save and evaluate the model \n",
    "            if (step - 1) % 200 == 0 or (step + 1) == FLAGS.max_steps or step == 1:\n",
    "                ## evaluate and save progress \n",
    "\n",
    "                steplist.append(step) # list of training steps\n",
    "                ## Evaluate against the training set.\n",
    "                feed_dict={images_placeholder: data.xtrain, activity_placeholder: data.ytrain, keep_prob_placeholder:1}\n",
    "                losstrain = sess.run(loss, feed_dict=feed_dict)\n",
    "                trainlist.append(losstrain) # list of loss on training set\n",
    "                ## Evaluate against the eval set.\n",
    "\n",
    "                feed_dict={images_placeholder: data.xeval, activity_placeholder: data.yeval, keep_prob_placeholder:1}\n",
    "                losseval = sess.run(loss, feed_dict=feed_dict)\n",
    "\n",
    "          \n",
    "                evallist.append(losseval) # list of loss on eval set\n",
    "                #computting r eval on eval set\n",
    "                actpredict_eval = sess.run(model.output, feed_dict=feed_dict)\n",
    "                reval= np.zeros(data.numcell)\n",
    "                for icell in range(data.numcell):\n",
    "                    reval[icell], peval = pearsonr(actpredict_eval[:,icell], data.yeval[:,icell])\n",
    "                    if np.isnan(reval[icell]):\n",
    "                        reval[icell] = 0\n",
    "                rcelllist.append(reval) # list of r eval on eval set\n",
    "                revalmean = np.mean(reval)\n",
    "                rmeanlist.append(revalmean) # list of  mean r eval on eval set\n",
    "                ## Evaluate againts early stop data\n",
    "                feed_dict={images_placeholder: data.xstop, activity_placeholder: data.ystop, keep_prob_placeholder:1}\n",
    "                lossearlystop = sess.run(loss, feed_dict=feed_dict)\n",
    "                earlystoplist.append(lossearlystop) # list of loss on early stop set\n",
    "\n",
    "                ## plot and save training\n",
    "                if FLAGS.savetraining:\n",
    "                    mansavefig(trainlist, earlystoplist, evallist, rmeanlist, steplist, lossbaseline)\n",
    "\n",
    "                ## Finding the minumum loss on the early stop data set\n",
    "                ## check if new early stop min. If so, treat as best trained nextwork \n",
    "                if lossearlystop < lossearlystopmin:  # check if early stop is new min \n",
    "                    lossearlystopmin =  lossearlystop # save loss as new minumum loss on the early stop data set\n",
    "                    FVEeval = 1 - losseval / lossbaseline\n",
    "                    lossevalmin = losseval\n",
    "                    print(\"early stop\")\n",
    "                    print(\"Performance is:\")\n",
    "                    print('squared (loss) = %.4f; FVE = %5.3f' % (losseval,FVEeval))\n",
    "\n",
    "                    # compute r val again. Could use above values. \n",
    "                    rval= np.zeros(data.numcell)\n",
    "                    feed_dict={images_placeholder: data.xeval, activity_placeholder: data.yeval, keep_prob_placeholder:1}\n",
    "                    loss_per_neuron_eval = sess.run(loss_per_neuron, feed_dict=feed_dict)\n",
    "                    actpredict_eval = sess.run(model.output, feed_dict=feed_dict)\n",
    "                    rval= np.zeros(data.numcell)\n",
    "                    for icell in range(data.numcell):\n",
    "                        rval[icell], pval = pearsonr(actpredict_eval[:,icell], data.yeval[:,icell])\n",
    "                        if np.isnan(rval[icell]):\n",
    "                            rval[icell] = 0\n",
    "                    rmean = np.mean(rval)\n",
    "                    print('r = %5.3f' % (rmean))\n",
    "                    print(\"More training!\")\n",
    "                    if FLAGS.savenetwork:\n",
    "                        network_save(step) #save the parameters of network\n",
    "                    if FLAGS.save:\n",
    "                        plotandsaver(rval, step, loss_per_neuron_eval, lossbaselineneuron) #save the performance of network \n",
    "\n",
    "        print(\"Final results\")\n",
    "        print(\"Best Performance: \")\n",
    "        print('r = %5.3f +- %5.3f;  squared (loss) = %.4f;  FVE = %5.3f' % (rmean, np.std(rval)/np.sqrt(data.numcell), losseval, FVEeval))\n",
    "        print(\"Evaluation Variance is:\") \n",
    "        print(np.mean(evalvar)) \n",
    "        rerror = np.std(rval)/np.sqrt(data.numcell)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_error(): \n",
    "    # make the baseline predictor\n",
    "    \n",
    "    meanactdum  = np.mean(data.ytrain, axis=0)\n",
    "\n",
    "    meanact =  np.reshape(meanactdum, [1, meanactdum.size])\n",
    "    meanpredict = np.repeat(meanact, data.numeval, axis=0)\n",
    "\n",
    "    #make placeholdfers for baseline \n",
    "    y_ = tf.placeholder(tf.float32, shape = (None, data.numcell))\n",
    "    meanpredict_placeholder = tf.placeholder(tf.float32, shape=(None,data.numcell))\n",
    "    loss_baseline = build_network.loss(meanpredict_placeholder,y_)\n",
    "    loss_baseline_percell = build_network.losspercell(meanpredict_placeholder,y_)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "\n",
    "    # Evaluate the baseline.\n",
    "    feed_dict={meanpredict_placeholder: meanpredict, y_: data.yeval}\n",
    "    loss_baseline_eval = sess.run(loss_baseline, feed_dict=feed_dict)\n",
    "    loss_baseline_eval_percell = sess.run(loss_baseline_percell, feed_dict=feed_dict)\n",
    "    #print and return baseline loss\n",
    "    print('')\n",
    "    print('Eval data baseline loss = %.4f' % (loss_baseline_eval))\n",
    "    print(\"variance of evaluation\")\n",
    "    vare = np.var(data.yeval, axis = 0)\n",
    "    print(np.shape(vare) )\n",
    "    print(np.mean(vare))\n",
    "    manvare = np.mean(np.mean(np.square(meanpredict-data.yeval)))\n",
    "    print(\"man calc variance/loss of evaluation\")\n",
    "    print(manvare)\n",
    "    return loss_baseline_eval, loss_baseline_eval_percell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotandsaver(rval,step, loss_per_neuron_eval, lossbaselineneuron):\n",
    "    figN, axN = plt.subplots()\n",
    "    bar_width = 0.40\n",
    "    xvals = np.arange(len(rval))+1-bar_width/2\n",
    "    axN.bar(xvals, rval)\n",
    "    axN.set_xlabel('cell', color='k')\n",
    "    axN.set_ylabel('r', color='k')\n",
    "    plt.savefig(pearsonsavedir)\n",
    "    traintrials = data.traintrials\n",
    "    earlystoptrials = data.earlystoptrials\n",
    "    evaltrials = data.evaltrials\n",
    "    np.save(pearsonsavedatadir,[rval,step,loss_per_neuron_eval,lossbaselineneuron, evalvar,traintrials,earlystoptrials,evaltrials,FLAGS])\n",
    "    plt.close(figN)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network_save(step):\n",
    "    print('saving network as: ' + savenetworkname)\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    #manually get all of the network parameters\n",
    "    with tf.variable_scope('conv1', reuse = True) as scope:\n",
    "        weights1 = tf.get_variable('W')\n",
    "        WC1 = sess.run(weights1)\n",
    "        biases1 = tf.get_variable('b')\n",
    "        BC1 =sess.run(biases1)\n",
    "    if FLAGS.numconvlayer != 1:\n",
    "        with tf.variable_scope('conv2', reuse = True) as scope:\n",
    "            weights2 = tf.get_variable('W')\n",
    "            WC2 = sess.run(weights2)\n",
    "            biases2 = tf.get_variable('b')\n",
    "            BC2 =sess.run(biases2)\n",
    "    with tf.variable_scope('dense1', reuse = True) as scope:\n",
    "        weights3 = tf.get_variable('W')\n",
    "        WH = sess.run(weights3)\n",
    "        biases3 = tf.get_variable('b')\n",
    "        BH = sess.run(biases3)\n",
    "    with tf.variable_scope('linear', reuse = True) as scope:\n",
    "        weights4 = tf.get_variable('W')\n",
    "        WL = sess.run(weights4)\n",
    "        biases4 = tf.get_variable('b')\n",
    "        BL = sess.run(biases4)\n",
    "    if FLAGS.numconvlayer == 1:\n",
    "        np.save(savenetworkname,[WC1, BC1, WH, BH, WL, BL, step])\n",
    "    else:\n",
    "        np.save(savenetworkname,[WC1, BC1, WC2, BC2, WH, BH, WL, BL, step])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mansavefig(trainlist, earlystoplist, evallist, rlist, step, lossbaseline):\n",
    "    plt.ioff()\n",
    "    minindex = np.argmin(np.asarray(earlystoplist))\n",
    "    xrange = max(step)\n",
    "    \n",
    "    textx = 100 + xrange/8\n",
    "    if (textx<step[minindex]) & (step[minindex]<xrange/2):\n",
    "        textx = xrange/12 + step[minindex]\n",
    "    ymax = 2.0*lossbaseline\n",
    "    ymin = -0.1*lossbaseline\n",
    "    deltay = ymax - ymin\n",
    "    figA, axA = plt.subplots()\n",
    "\n",
    "    axA.plot(np.asarray(step), np.asarray(trainlist), 'r', label='training')\n",
    "    axA.plot(np.asarray(step), np.asarray(earlystoplist), 'r--', label = 'early stop')\n",
    "    axA.plot(np.asarray(step), np.asarray(evallist), 'r:', label = 'evaluation')\n",
    "    axA.set_ylim([ymin,ymax])\n",
    "    axA.set_xlabel('step')\n",
    "      ## Make the y-axis label, ticks and tick labels match the line color.\n",
    "    axA.axvline(x = step[minindex], ymin = -0.1, ymax = 2, linewidth = 2, color = 'k')\n",
    "    axA.set_ylabel('least squared loss', color = 'k')\n",
    "    axA.tick_params('y', colors = 'k')\n",
    "    axA.annotate('Step: %d' % (step[minindex] ), xy = (textx, 1.0*deltay+ymin))\n",
    "    axA.annotate('avg r: %.3f; eval loss %.4f / eval var %.4f' % (np.mean(rlist[minindex]),np.mean(evallist[minindex]), np.mean(evalvar) ), xy=(textx, 0.95*deltay+ymin))\n",
    "    axA.annotate('Max pool 1 stride: %d ' % (FLAGS.nstride1), xy=(textx, 0.90*deltay+ymin))\n",
    "    axA.annotate('Max pool 1 kernel size: %d ' % (FLAGS.nk1), xy=(textx, 0.85*deltay+ymin))\n",
    "    axA.annotate('Conv 1 size: %d X %d ' % (FLAGS.conv1size, FLAGS.conv1size), xy=(textx, 0.80*deltay+ymin))\n",
    "    axA.annotate('number of L 1 filters: %d' % (FLAGS.conv1), xy=(textx, 0.75*deltay+ymin))\n",
    "    axA.annotate('Max pool 2 stride: %d ' % (FLAGS.nstride2), xy=(textx, 0.70*deltay+ymin))\n",
    "    axA.annotate('Max pool 2 kernel size: %d ' % (FLAGS.nk2), xy=(textx, 0.65*deltay+ymin))\n",
    "    axA.annotate('Conv 2 size: %d X %d ' % (FLAGS.conv2size, FLAGS.conv2size), xy=(textx, 0.60*deltay+ymin))\n",
    "    axA.annotate('number of L 2 filters: %d' % (FLAGS.conv2), xy=(textx, 0.55*deltay+ymin))\n",
    "    axA.annotate('Dropout keep rate: %.3f ' % (FLAGS.dropout), xy=(textx, 0.50*deltay+ymin))\n",
    "    axA.annotate('%d hidden elements' % (FLAGS.hidden1 ), xy=(textx, 0.45*deltay+ymin))\n",
    "    axA.annotate('Learning rate: %.1e' % (FLAGS.learning_rate), xy=(textx, 0.40*deltay+ymin))\n",
    "    axA.annotate('Num conv layers: %d ' % (FLAGS.numconvlayer), xy=(textx, 0.35*deltay+ymin))\n",
    "    \n",
    "    plt.legend(loc = 'best')\n",
    "    axB = axA.twinx()\n",
    "    axB.plot(np.asarray(step), np.asarray(rlist), 'k')\n",
    "    axB.set_ylim([-0.1,1])\n",
    "    axB.set_ylabel('r', color = 'k')\n",
    "    axB.tick_params('y', colors = 'k')\n",
    "    figA.tight_layout()\n",
    "    plt.savefig(savefigname)\n",
    "    plt.close(figA)\n",
    "\n",
    "    ##saving training parameters\n",
    "    traintrials = data.traintrials\n",
    "    earlystoptrials = data.earlystoptrials\n",
    "    evaltrials = data.evaltrials\n",
    "    np.save(savedirname,[FLAGS, trainlist, earlystoplist, evallist, rlist,\n",
    "        step, lossbaseline, traintrials, earlystoptrials, evaltrials])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eval data baseline loss = 0.2007\n",
      "variance of evaluation\n",
      "(37,)\n",
      "0.1966469344714537\n",
      "man calc variance/loss of evaluation\n",
      "0.20070449167115834\n",
      "start building network\n",
      "building layer conv1\n",
      "with 16 filters shaped \n",
      "[3, 3, 1, 16]\n",
      "curret layer is \n",
      "Tensor(\"conv1/pool:0\", shape=(?, 15, 15, 16), dtype=float32)\n",
      "building layer conv2\n",
      "with 32 filters shaped \n",
      "[3, 3, 16, 32]\n",
      "curret layer is \n",
      "Tensor(\"conv2/pool:0\", shape=(?, 6, 6, 32), dtype=float32)\n",
      "building layer dense1\n",
      "maping 1152 elemements to 300 elements\n",
      "building linear layer\n",
      "linear maping 300 elemements to 37 elements\n",
      "Finished building network\n",
      "model shape is\n",
      "(?, 37)\n",
      "Step 0: loss = 0.7946; FVE = -2.96 (1.348 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ola-sammy/anaconda/lib/python3.6/site-packages/scipy/stats/stats.py:3003: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.7587; FVE = -2.780\n",
      "r = 0.033\n",
      "More training!\n",
      "Step 50: loss = 0.4960; FVE = -1.47 (0.022 sec)\n",
      "Step 100: loss = 0.3413; FVE = -0.70 (0.028 sec)\n",
      "Step 150: loss = 0.3527; FVE = -0.76 (0.029 sec)\n",
      "Step 200: loss = 0.2574; FVE = -0.28 (0.029 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.2095; FVE = -0.044\n",
      "r = 0.085\n",
      "More training!\n",
      "Step 250: loss = 0.2454; FVE = -0.22 (0.023 sec)\n",
      "Step 300: loss = 0.2557; FVE = -0.27 (0.024 sec)\n",
      "Step 350: loss = 0.2463; FVE = -0.23 (0.024 sec)\n",
      "Step 400: loss = 0.2381; FVE = -0.19 (0.034 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1965; FVE = 0.021\n",
      "r = 0.135\n",
      "More training!\n",
      "Step 450: loss = 0.2399; FVE = -0.20 (0.023 sec)\n",
      "Step 500: loss = 0.2341; FVE = -0.17 (0.029 sec)\n",
      "Step 550: loss = 0.2352; FVE = -0.17 (0.029 sec)\n",
      "Step 600: loss = 0.2065; FVE = -0.03 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1850; FVE = 0.078\n",
      "r = 0.204\n",
      "More training!\n",
      "Step 650: loss = 0.2063; FVE = -0.03 (0.025 sec)\n",
      "Step 700: loss = 0.1971; FVE =  0.02 (0.028 sec)\n",
      "Step 750: loss = 0.2206; FVE = -0.10 (0.025 sec)\n",
      "Step 800: loss = 0.2062; FVE = -0.03 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1753; FVE = 0.127\n",
      "r = 0.277\n",
      "More training!\n",
      "Step 850: loss = 0.1995; FVE =  0.01 (0.024 sec)\n",
      "Step 900: loss = 0.1891; FVE =  0.06 (0.033 sec)\n",
      "Step 950: loss = 0.2085; FVE = -0.04 (0.025 sec)\n",
      "Step 1000: loss = 0.1880; FVE =  0.06 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1686; FVE = 0.160\n",
      "r = 0.331\n",
      "More training!\n",
      "Step 1050: loss = 0.1951; FVE =  0.03 (0.028 sec)\n",
      "Step 1100: loss = 0.1628; FVE =  0.19 (0.024 sec)\n",
      "Step 1150: loss = 0.1646; FVE =  0.18 (0.022 sec)\n",
      "Step 1200: loss = 0.1689; FVE =  0.16 (0.026 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1627; FVE = 0.189\n",
      "r = 0.374\n",
      "More training!\n",
      "Step 1250: loss = 0.1751; FVE =  0.13 (0.021 sec)\n",
      "Step 1300: loss = 0.1867; FVE =  0.07 (0.025 sec)\n",
      "Step 1350: loss = 0.1643; FVE =  0.18 (0.040 sec)\n",
      "Step 1400: loss = 0.1647; FVE =  0.18 (0.059 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1580; FVE = 0.213\n",
      "r = 0.407\n",
      "More training!\n",
      "Step 1450: loss = 0.1657; FVE =  0.17 (0.056 sec)\n",
      "Step 1500: loss = 0.1693; FVE =  0.16 (0.026 sec)\n",
      "Step 1550: loss = 0.1829; FVE =  0.09 (0.021 sec)\n",
      "Step 1600: loss = 0.1746; FVE =  0.13 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1554; FVE = 0.226\n",
      "r = 0.427\n",
      "More training!\n",
      "Step 1650: loss = 0.1585; FVE =  0.21 (0.023 sec)\n",
      "Step 1700: loss = 0.1534; FVE =  0.24 (0.025 sec)\n",
      "Step 1750: loss = 0.1712; FVE =  0.15 (0.023 sec)\n",
      "Step 1800: loss = 0.1734; FVE =  0.14 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1518; FVE = 0.244\n",
      "r = 0.445\n",
      "More training!\n",
      "Step 1850: loss = 0.1678; FVE =  0.16 (0.061 sec)\n",
      "Step 1900: loss = 0.1494; FVE =  0.26 (0.023 sec)\n",
      "Step 1950: loss = 0.1616; FVE =  0.20 (0.032 sec)\n",
      "Step 2000: loss = 0.1675; FVE =  0.17 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1501; FVE = 0.252\n",
      "r = 0.456\n",
      "More training!\n",
      "Step 2050: loss = 0.1667; FVE =  0.17 (0.034 sec)\n",
      "Step 2100: loss = 0.1510; FVE =  0.25 (0.033 sec)\n",
      "Step 2150: loss = 0.1628; FVE =  0.19 (0.025 sec)\n",
      "Step 2200: loss = 0.1665; FVE =  0.17 (0.025 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1480; FVE = 0.263\n",
      "r = 0.466\n",
      "More training!\n",
      "Step 2250: loss = 0.1671; FVE =  0.17 (0.024 sec)\n",
      "Step 2300: loss = 0.1393; FVE =  0.31 (0.026 sec)\n",
      "Step 2350: loss = 0.1537; FVE =  0.23 (0.021 sec)\n",
      "Step 2400: loss = 0.1425; FVE =  0.29 (0.044 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1465; FVE = 0.270\n",
      "r = 0.475\n",
      "More training!\n",
      "Step 2450: loss = 0.1612; FVE =  0.20 (0.021 sec)\n",
      "Step 2500: loss = 0.1394; FVE =  0.31 (0.025 sec)\n",
      "Step 2550: loss = 0.1594; FVE =  0.21 (0.025 sec)\n",
      "Step 2600: loss = 0.1688; FVE =  0.16 (0.020 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1449; FVE = 0.278\n",
      "r = 0.482\n",
      "More training!\n",
      "Step 2650: loss = 0.1475; FVE =  0.27 (0.021 sec)\n",
      "Step 2700: loss = 0.1622; FVE =  0.19 (0.023 sec)\n",
      "Step 2750: loss = 0.1394; FVE =  0.31 (0.023 sec)\n",
      "Step 2800: loss = 0.1657; FVE =  0.17 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1433; FVE = 0.286\n",
      "r = 0.489\n",
      "More training!\n",
      "Step 2850: loss = 0.1344; FVE =  0.33 (0.020 sec)\n",
      "Step 2900: loss = 0.1589; FVE =  0.21 (0.020 sec)\n",
      "Step 2950: loss = 0.1233; FVE =  0.39 (0.025 sec)\n",
      "Step 3000: loss = 0.1575; FVE =  0.22 (0.041 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1419; FVE = 0.293\n",
      "r = 0.495\n",
      "More training!\n",
      "Step 3050: loss = 0.1351; FVE =  0.33 (0.020 sec)\n",
      "Step 3100: loss = 0.1389; FVE =  0.31 (0.024 sec)\n",
      "Step 3150: loss = 0.1442; FVE =  0.28 (0.022 sec)\n",
      "Step 3200: loss = 0.1502; FVE =  0.25 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1403; FVE = 0.301\n",
      "r = 0.500\n",
      "More training!\n",
      "Step 3250: loss = 0.1303; FVE =  0.35 (0.022 sec)\n",
      "Step 3300: loss = 0.1467; FVE =  0.27 (0.024 sec)\n",
      "Step 3350: loss = 0.1412; FVE =  0.30 (0.025 sec)\n",
      "Step 3400: loss = 0.1327; FVE =  0.34 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1391; FVE = 0.307\n",
      "r = 0.506\n",
      "More training!\n",
      "Step 3450: loss = 0.1472; FVE =  0.27 (0.019 sec)\n",
      "Step 3500: loss = 0.1520; FVE =  0.24 (0.020 sec)\n",
      "Step 3550: loss = 0.1521; FVE =  0.24 (0.036 sec)\n",
      "Step 3600: loss = 0.1463; FVE =  0.27 (0.028 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1383; FVE = 0.311\n",
      "r = 0.510\n",
      "More training!\n",
      "Step 3650: loss = 0.1333; FVE =  0.34 (0.019 sec)\n",
      "Step 3700: loss = 0.1213; FVE =  0.40 (0.024 sec)\n",
      "Step 3750: loss = 0.1308; FVE =  0.35 (0.023 sec)\n",
      "Step 3800: loss = 0.1388; FVE =  0.31 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1372; FVE = 0.317\n",
      "r = 0.513\n",
      "More training!\n",
      "Step 3850: loss = 0.1349; FVE =  0.33 (0.025 sec)\n",
      "Step 3900: loss = 0.1463; FVE =  0.27 (0.026 sec)\n",
      "Step 3950: loss = 0.1324; FVE =  0.34 (0.023 sec)\n",
      "Step 4000: loss = 0.1428; FVE =  0.29 (0.026 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1358; FVE = 0.323\n",
      "r = 0.518\n",
      "More training!\n",
      "Step 4050: loss = 0.1281; FVE =  0.36 (0.021 sec)\n",
      "Step 4100: loss = 0.1383; FVE =  0.31 (0.023 sec)\n",
      "Step 4150: loss = 0.1500; FVE =  0.25 (0.021 sec)\n",
      "Step 4200: loss = 0.1360; FVE =  0.32 (0.036 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1344; FVE = 0.330\n",
      "r = 0.523\n",
      "More training!\n",
      "Step 4250: loss = 0.1353; FVE =  0.33 (0.022 sec)\n",
      "Step 4300: loss = 0.1434; FVE =  0.29 (0.024 sec)\n",
      "Step 4350: loss = 0.1503; FVE =  0.25 (0.028 sec)\n",
      "Step 4400: loss = 0.1276; FVE =  0.36 (0.025 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1340; FVE = 0.332\n",
      "r = 0.524\n",
      "More training!\n",
      "Step 4450: loss = 0.1392; FVE =  0.31 (0.022 sec)\n",
      "Step 4500: loss = 0.1475; FVE =  0.27 (0.022 sec)\n",
      "Step 4550: loss = 0.1342; FVE =  0.33 (0.026 sec)\n",
      "Step 4600: loss = 0.1245; FVE =  0.38 (0.028 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1324; FVE = 0.340\n",
      "r = 0.527\n",
      "More training!\n",
      "Step 4650: loss = 0.1215; FVE =  0.39 (0.021 sec)\n",
      "Step 4700: loss = 0.1314; FVE =  0.35 (0.026 sec)\n",
      "Step 4750: loss = 0.1362; FVE =  0.32 (0.036 sec)\n",
      "Step 4800: loss = 0.1292; FVE =  0.36 (0.026 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1319; FVE = 0.343\n",
      "r = 0.531\n",
      "More training!\n",
      "Step 4850: loss = 0.1455; FVE =  0.28 (0.027 sec)\n",
      "Step 4900: loss = 0.1345; FVE =  0.33 (0.027 sec)\n",
      "Step 4950: loss = 0.1321; FVE =  0.34 (0.028 sec)\n",
      "Step 5000: loss = 0.1208; FVE =  0.40 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1305; FVE = 0.350\n",
      "r = 0.533\n",
      "More training!\n",
      "Step 5050: loss = 0.1283; FVE =  0.36 (0.026 sec)\n",
      "Step 5100: loss = 0.1336; FVE =  0.33 (0.023 sec)\n",
      "Step 5150: loss = 0.1247; FVE =  0.38 (0.022 sec)\n",
      "Step 5200: loss = 0.1322; FVE =  0.34 (0.028 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1298; FVE = 0.353\n",
      "r = 0.535\n",
      "More training!\n",
      "Step 5250: loss = 0.1297; FVE =  0.35 (0.023 sec)\n",
      "Step 5300: loss = 0.1360; FVE =  0.32 (0.027 sec)\n",
      "Step 5350: loss = 0.1247; FVE =  0.38 (0.034 sec)\n",
      "Step 5400: loss = 0.1302; FVE =  0.35 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1288; FVE = 0.358\n",
      "r = 0.538\n",
      "More training!\n",
      "Step 5450: loss = 0.1220; FVE =  0.39 (0.023 sec)\n",
      "Step 5500: loss = 0.1259; FVE =  0.37 (0.023 sec)\n",
      "Step 5550: loss = 0.1224; FVE =  0.39 (0.023 sec)\n",
      "Step 5600: loss = 0.1197; FVE =  0.40 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1284; FVE = 0.360\n",
      "r = 0.540\n",
      "More training!\n",
      "Step 5650: loss = 0.1261; FVE =  0.37 (0.024 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5700: loss = 0.1251; FVE =  0.38 (0.024 sec)\n",
      "Step 5750: loss = 0.1310; FVE =  0.35 (0.024 sec)\n",
      "Step 5800: loss = 0.1251; FVE =  0.38 (0.026 sec)\n",
      "Step 5850: loss = 0.1290; FVE =  0.36 (0.026 sec)\n",
      "Step 5900: loss = 0.1158; FVE =  0.42 (0.022 sec)\n",
      "Step 5950: loss = 0.1154; FVE =  0.43 (0.036 sec)\n",
      "Step 6000: loss = 0.1205; FVE =  0.40 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1264; FVE = 0.370\n",
      "r = 0.545\n",
      "More training!\n",
      "Step 6050: loss = 0.1260; FVE =  0.37 (0.021 sec)\n",
      "Step 6100: loss = 0.1202; FVE =  0.40 (0.021 sec)\n",
      "Step 6150: loss = 0.1301; FVE =  0.35 (0.022 sec)\n",
      "Step 6200: loss = 0.1081; FVE =  0.46 (0.020 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1258; FVE = 0.373\n",
      "r = 0.547\n",
      "More training!\n",
      "Step 6250: loss = 0.1186; FVE =  0.41 (0.025 sec)\n",
      "Step 6300: loss = 0.1282; FVE =  0.36 (0.023 sec)\n",
      "Step 6350: loss = 0.1109; FVE =  0.45 (0.024 sec)\n",
      "Step 6400: loss = 0.1168; FVE =  0.42 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1246; FVE = 0.379\n",
      "r = 0.549\n",
      "More training!\n",
      "Step 6450: loss = 0.1228; FVE =  0.39 (0.025 sec)\n",
      "Step 6500: loss = 0.1270; FVE =  0.37 (0.031 sec)\n",
      "Step 6550: loss = 0.1200; FVE =  0.40 (0.033 sec)\n",
      "Step 6600: loss = 0.1139; FVE =  0.43 (0.020 sec)\n",
      "Step 6650: loss = 0.1240; FVE =  0.38 (0.021 sec)\n",
      "Step 6700: loss = 0.1135; FVE =  0.43 (0.023 sec)\n",
      "Step 6750: loss = 0.1245; FVE =  0.38 (0.023 sec)\n",
      "Step 6800: loss = 0.1195; FVE =  0.40 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1239; FVE = 0.383\n",
      "r = 0.553\n",
      "More training!\n",
      "Step 6850: loss = 0.1224; FVE =  0.39 (0.023 sec)\n",
      "Step 6900: loss = 0.1228; FVE =  0.39 (0.024 sec)\n",
      "Step 6950: loss = 0.1171; FVE =  0.42 (0.020 sec)\n",
      "Step 7000: loss = 0.1139; FVE =  0.43 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1236; FVE = 0.384\n",
      "r = 0.555\n",
      "More training!\n",
      "Step 7050: loss = 0.1121; FVE =  0.44 (0.022 sec)\n",
      "Step 7100: loss = 0.1194; FVE =  0.40 (0.025 sec)\n",
      "Step 7150: loss = 0.1121; FVE =  0.44 (0.046 sec)\n",
      "Step 7200: loss = 0.1177; FVE =  0.41 (0.019 sec)\n",
      "Step 7250: loss = 0.1141; FVE =  0.43 (0.024 sec)\n",
      "Step 7300: loss = 0.1133; FVE =  0.44 (0.022 sec)\n",
      "Step 7350: loss = 0.1090; FVE =  0.46 (0.023 sec)\n",
      "Step 7400: loss = 0.1191; FVE =  0.41 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1214; FVE = 0.395\n",
      "r = 0.559\n",
      "More training!\n",
      "Step 7450: loss = 0.1195; FVE =  0.40 (0.022 sec)\n",
      "Step 7500: loss = 0.1024; FVE =  0.49 (0.020 sec)\n",
      "Step 7550: loss = 0.1199; FVE =  0.40 (0.021 sec)\n",
      "Step 7600: loss = 0.1088; FVE =  0.46 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1209; FVE = 0.398\n",
      "r = 0.560\n",
      "More training!\n",
      "Step 7650: loss = 0.1140; FVE =  0.43 (0.026 sec)\n",
      "Step 7700: loss = 0.1121; FVE =  0.44 (0.020 sec)\n",
      "Step 7750: loss = 0.0949; FVE =  0.53 (0.034 sec)\n",
      "Step 7800: loss = 0.1118; FVE =  0.44 (0.020 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1200; FVE = 0.402\n",
      "r = 0.562\n",
      "More training!\n",
      "Step 7850: loss = 0.1182; FVE =  0.41 (0.022 sec)\n",
      "Step 7900: loss = 0.1201; FVE =  0.40 (0.025 sec)\n",
      "Step 7950: loss = 0.1143; FVE =  0.43 (0.021 sec)\n",
      "Step 8000: loss = 0.1037; FVE =  0.48 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1197; FVE = 0.404\n",
      "r = 0.564\n",
      "More training!\n",
      "Step 8050: loss = 0.1030; FVE =  0.49 (0.021 sec)\n",
      "Step 8100: loss = 0.1134; FVE =  0.44 (0.024 sec)\n",
      "Step 8150: loss = 0.1084; FVE =  0.46 (0.022 sec)\n",
      "Step 8200: loss = 0.1062; FVE =  0.47 (0.022 sec)\n",
      "Step 8250: loss = 0.1120; FVE =  0.44 (0.024 sec)\n",
      "Step 8300: loss = 0.1032; FVE =  0.49 (0.035 sec)\n",
      "Step 8350: loss = 0.1017; FVE =  0.49 (0.041 sec)\n",
      "Step 8400: loss = 0.1092; FVE =  0.46 (0.021 sec)\n",
      "Step 8450: loss = 0.1070; FVE =  0.47 (0.022 sec)\n",
      "Step 8500: loss = 0.1147; FVE =  0.43 (0.022 sec)\n",
      "Step 8550: loss = 0.1259; FVE =  0.37 (0.023 sec)\n",
      "Step 8600: loss = 0.1120; FVE =  0.44 (0.020 sec)\n",
      "Step 8650: loss = 0.1105; FVE =  0.45 (0.025 sec)\n",
      "Step 8700: loss = 0.1078; FVE =  0.46 (0.021 sec)\n",
      "Step 8750: loss = 0.1002; FVE =  0.50 (0.026 sec)\n",
      "Step 8800: loss = 0.1068; FVE =  0.47 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1175; FVE = 0.415\n",
      "r = 0.571\n",
      "More training!\n",
      "Step 8850: loss = 0.1046; FVE =  0.48 (0.024 sec)\n",
      "Step 8900: loss = 0.1109; FVE =  0.45 (0.037 sec)\n",
      "Step 8950: loss = 0.1030; FVE =  0.49 (0.041 sec)\n",
      "Step 9000: loss = 0.1028; FVE =  0.49 (0.021 sec)\n",
      "Step 9050: loss = 0.1046; FVE =  0.48 (0.023 sec)\n",
      "Step 9100: loss = 0.1006; FVE =  0.50 (0.025 sec)\n",
      "Step 9150: loss = 0.1151; FVE =  0.43 (0.023 sec)\n",
      "Step 9200: loss = 0.1074; FVE =  0.46 (0.026 sec)\n",
      "Step 9250: loss = 0.1092; FVE =  0.46 (0.021 sec)\n",
      "Step 9300: loss = 0.1083; FVE =  0.46 (0.021 sec)\n",
      "Step 9350: loss = 0.1102; FVE =  0.45 (0.023 sec)\n",
      "Step 9400: loss = 0.1024; FVE =  0.49 (0.026 sec)\n",
      "Step 9450: loss = 0.1061; FVE =  0.47 (0.021 sec)\n",
      "Step 9500: loss = 0.1064; FVE =  0.47 (0.024 sec)\n",
      "Step 9550: loss = 0.1018; FVE =  0.49 (0.039 sec)\n",
      "Step 9600: loss = 0.0978; FVE =  0.51 (0.021 sec)\n",
      "Step 9650: loss = 0.1008; FVE =  0.50 (0.020 sec)\n",
      "Step 9700: loss = 0.1015; FVE =  0.49 (0.021 sec)\n",
      "Step 9750: loss = 0.1124; FVE =  0.44 (0.021 sec)\n",
      "Step 9800: loss = 0.1027; FVE =  0.49 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1146; FVE = 0.429\n",
      "r = 0.578\n",
      "More training!\n",
      "Step 9850: loss = 0.0990; FVE =  0.51 (0.022 sec)\n",
      "Step 9900: loss = 0.1094; FVE =  0.46 (0.024 sec)\n",
      "Step 9950: loss = 0.0911; FVE =  0.55 (0.023 sec)\n",
      "Step 10000: loss = 0.1106; FVE =  0.45 (0.025 sec)\n",
      "Step 10050: loss = 0.0983; FVE =  0.51 (0.022 sec)\n",
      "Step 10100: loss = 0.1054; FVE =  0.47 (0.021 sec)\n",
      "Step 10150: loss = 0.1040; FVE =  0.48 (0.033 sec)\n",
      "Step 10200: loss = 0.1057; FVE =  0.47 (0.024 sec)\n",
      "Step 10250: loss = 0.1027; FVE =  0.49 (0.021 sec)\n",
      "Step 10300: loss = 0.0945; FVE =  0.53 (0.022 sec)\n",
      "Step 10350: loss = 0.0933; FVE =  0.54 (0.024 sec)\n",
      "Step 10400: loss = 0.0987; FVE =  0.51 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1136; FVE = 0.434\n",
      "r = 0.583\n",
      "More training!\n",
      "Step 10450: loss = 0.1021; FVE =  0.49 (0.022 sec)\n",
      "Step 10500: loss = 0.0998; FVE =  0.50 (0.020 sec)\n",
      "Step 10550: loss = 0.1065; FVE =  0.47 (0.022 sec)\n",
      "Step 10600: loss = 0.1012; FVE =  0.50 (0.026 sec)\n",
      "Step 10650: loss = 0.1013; FVE =  0.50 (0.022 sec)\n",
      "Step 10700: loss = 0.0997; FVE =  0.50 (0.022 sec)\n",
      "Step 10750: loss = 0.0905; FVE =  0.55 (0.037 sec)\n",
      "Step 10800: loss = 0.0887; FVE =  0.56 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1120; FVE = 0.442\n",
      "r = 0.585\n",
      "More training!\n",
      "Step 10850: loss = 0.0958; FVE =  0.52 (0.024 sec)\n",
      "Step 10900: loss = 0.0983; FVE =  0.51 (0.022 sec)\n",
      "Step 10950: loss = 0.0997; FVE =  0.50 (0.023 sec)\n",
      "Step 11000: loss = 0.0857; FVE =  0.57 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1119; FVE = 0.442\n",
      "r = 0.586\n",
      "More training!\n",
      "Step 11050: loss = 0.0938; FVE =  0.53 (0.023 sec)\n",
      "Step 11100: loss = 0.0978; FVE =  0.51 (0.023 sec)\n",
      "Step 11150: loss = 0.0907; FVE =  0.55 (0.022 sec)\n",
      "Step 11200: loss = 0.1028; FVE =  0.49 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1124; FVE = 0.440\n",
      "r = 0.587\n",
      "More training!\n",
      "Step 11250: loss = 0.0905; FVE =  0.55 (0.022 sec)\n",
      "Step 11300: loss = 0.0874; FVE =  0.56 (0.022 sec)\n",
      "Step 11350: loss = 0.0949; FVE =  0.53 (0.040 sec)\n",
      "Step 11400: loss = 0.1002; FVE =  0.50 (0.025 sec)\n",
      "Step 11450: loss = 0.0987; FVE =  0.51 (0.026 sec)\n",
      "Step 11500: loss = 0.0870; FVE =  0.57 (0.023 sec)\n",
      "Step 11550: loss = 0.0940; FVE =  0.53 (0.021 sec)\n",
      "Step 11600: loss = 0.1047; FVE =  0.48 (0.024 sec)\n",
      "Step 11650: loss = 0.0979; FVE =  0.51 (0.022 sec)\n",
      "Step 11700: loss = 0.0883; FVE =  0.56 (0.022 sec)\n",
      "Step 11750: loss = 0.1000; FVE =  0.50 (0.025 sec)\n",
      "Step 11800: loss = 0.0921; FVE =  0.54 (0.025 sec)\n",
      "Step 11850: loss = 0.0907; FVE =  0.55 (0.024 sec)\n",
      "Step 11900: loss = 0.0946; FVE =  0.53 (0.021 sec)\n",
      "Step 11950: loss = 0.0973; FVE =  0.52 (0.039 sec)\n",
      "Step 12000: loss = 0.0976; FVE =  0.51 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1107; FVE = 0.448\n",
      "r = 0.590\n",
      "More training!\n",
      "Step 12050: loss = 0.0931; FVE =  0.54 (0.022 sec)\n",
      "Step 12100: loss = 0.1055; FVE =  0.47 (0.021 sec)\n",
      "Step 12150: loss = 0.0897; FVE =  0.55 (0.024 sec)\n",
      "Step 12200: loss = 0.0887; FVE =  0.56 (0.027 sec)\n",
      "Step 12250: loss = 0.0922; FVE =  0.54 (0.026 sec)\n",
      "Step 12300: loss = 0.0869; FVE =  0.57 (0.024 sec)\n",
      "Step 12350: loss = 0.0881; FVE =  0.56 (0.024 sec)\n",
      "Step 12400: loss = 0.0904; FVE =  0.55 (0.027 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1099; FVE = 0.452\n",
      "r = 0.593\n",
      "More training!\n",
      "Step 12450: loss = 0.0877; FVE =  0.56 (0.022 sec)\n",
      "Step 12500: loss = 0.0958; FVE =  0.52 (0.024 sec)\n",
      "Step 12550: loss = 0.0912; FVE =  0.55 (0.040 sec)\n",
      "Step 12600: loss = 0.1007; FVE =  0.50 (0.021 sec)\n",
      "Step 12650: loss = 0.0917; FVE =  0.54 (0.023 sec)\n",
      "Step 12700: loss = 0.0957; FVE =  0.52 (0.021 sec)\n",
      "Step 12750: loss = 0.0842; FVE =  0.58 (0.021 sec)\n",
      "Step 12800: loss = 0.0887; FVE =  0.56 (0.022 sec)\n",
      "Step 12850: loss = 0.0984; FVE =  0.51 (0.022 sec)\n",
      "Step 12900: loss = 0.0851; FVE =  0.58 (0.023 sec)\n",
      "Step 12950: loss = 0.0907; FVE =  0.55 (0.026 sec)\n",
      "Step 13000: loss = 0.0905; FVE =  0.55 (0.020 sec)\n",
      "Step 13050: loss = 0.0886; FVE =  0.56 (0.023 sec)\n",
      "Step 13100: loss = 0.0803; FVE =  0.60 (0.025 sec)\n",
      "Step 13150: loss = 0.0957; FVE =  0.52 (0.034 sec)\n",
      "Step 13200: loss = 0.0844; FVE =  0.58 (0.038 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1077; FVE = 0.463\n",
      "r = 0.596\n",
      "More training!\n",
      "Step 13250: loss = 0.0948; FVE =  0.53 (0.026 sec)\n",
      "Step 13300: loss = 0.0796; FVE =  0.60 (0.024 sec)\n",
      "Step 13350: loss = 0.0871; FVE =  0.57 (0.023 sec)\n",
      "Step 13400: loss = 0.0926; FVE =  0.54 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1075; FVE = 0.464\n",
      "r = 0.598\n",
      "More training!\n",
      "Step 13450: loss = 0.0856; FVE =  0.57 (0.024 sec)\n",
      "Step 13500: loss = 0.0900; FVE =  0.55 (0.028 sec)\n",
      "Step 13550: loss = 0.0885; FVE =  0.56 (0.023 sec)\n",
      "Step 13600: loss = 0.0827; FVE =  0.59 (0.026 sec)\n",
      "Step 13650: loss = 0.0910; FVE =  0.55 (0.028 sec)\n",
      "Step 13700: loss = 0.0885; FVE =  0.56 (0.044 sec)\n",
      "Step 13750: loss = 0.0837; FVE =  0.58 (0.023 sec)\n",
      "Step 13800: loss = 0.0887; FVE =  0.56 (0.027 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1073; FVE = 0.465\n",
      "r = 0.599\n",
      "More training!\n",
      "Step 13850: loss = 0.0808; FVE =  0.60 (0.027 sec)\n",
      "Step 13900: loss = 0.0874; FVE =  0.56 (0.026 sec)\n",
      "Step 13950: loss = 0.0954; FVE =  0.52 (0.022 sec)\n",
      "Step 14000: loss = 0.0897; FVE =  0.55 (0.021 sec)\n",
      "Step 14050: loss = 0.0788; FVE =  0.61 (0.023 sec)\n",
      "Step 14100: loss = 0.0889; FVE =  0.56 (0.021 sec)\n",
      "Step 14150: loss = 0.0790; FVE =  0.61 (0.027 sec)\n",
      "Step 14200: loss = 0.0847; FVE =  0.58 (0.021 sec)\n",
      "Step 14250: loss = 0.0799; FVE =  0.60 (0.023 sec)\n",
      "Step 14300: loss = 0.0804; FVE =  0.60 (0.030 sec)\n",
      "Step 14350: loss = 0.0810; FVE =  0.60 (0.031 sec)\n",
      "Step 14400: loss = 0.0881; FVE =  0.56 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1062; FVE = 0.471\n",
      "r = 0.601\n",
      "More training!\n",
      "Step 14450: loss = 0.0855; FVE =  0.57 (0.023 sec)\n",
      "Step 14500: loss = 0.0856; FVE =  0.57 (0.020 sec)\n",
      "Step 14550: loss = 0.0864; FVE =  0.57 (0.021 sec)\n",
      "Step 14600: loss = 0.0804; FVE =  0.60 (0.020 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1062; FVE = 0.471\n",
      "r = 0.603\n",
      "More training!\n",
      "Step 14650: loss = 0.0890; FVE =  0.56 (0.024 sec)\n",
      "Step 14700: loss = 0.0831; FVE =  0.59 (0.020 sec)\n",
      "Step 14750: loss = 0.0782; FVE =  0.61 (0.021 sec)\n",
      "Step 14800: loss = 0.0841; FVE =  0.58 (0.023 sec)\n",
      "Step 14850: loss = 0.0845; FVE =  0.58 (0.021 sec)\n",
      "Step 14900: loss = 0.0887; FVE =  0.56 (0.041 sec)\n",
      "Step 14950: loss = 0.0859; FVE =  0.57 (0.037 sec)\n",
      "Step 15000: loss = 0.0787; FVE =  0.61 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1054; FVE = 0.475\n",
      "r = 0.604\n",
      "More training!\n",
      "Step 15050: loss = 0.0803; FVE =  0.60 (0.023 sec)\n",
      "Step 15100: loss = 0.0828; FVE =  0.59 (0.021 sec)\n",
      "Step 15150: loss = 0.0792; FVE =  0.61 (0.022 sec)\n",
      "Step 15200: loss = 0.0855; FVE =  0.57 (0.020 sec)\n",
      "Step 15250: loss = 0.0789; FVE =  0.61 (0.021 sec)\n",
      "Step 15300: loss = 0.0702; FVE =  0.65 (0.023 sec)\n",
      "Step 15350: loss = 0.0876; FVE =  0.56 (0.026 sec)\n",
      "Step 15400: loss = 0.0713; FVE =  0.64 (0.024 sec)\n",
      "Step 15450: loss = 0.0837; FVE =  0.58 (0.021 sec)\n",
      "Step 15500: loss = 0.0837; FVE =  0.58 (0.019 sec)\n",
      "Step 15550: loss = 0.0750; FVE =  0.63 (0.037 sec)\n",
      "Step 15600: loss = 0.0803; FVE =  0.60 (0.020 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1042; FVE = 0.481\n",
      "r = 0.606\n",
      "More training!\n",
      "Step 15650: loss = 0.0748; FVE =  0.63 (0.024 sec)\n",
      "Step 15700: loss = 0.0790; FVE =  0.61 (0.022 sec)\n",
      "Step 15750: loss = 0.0830; FVE =  0.59 (0.025 sec)\n",
      "Step 15800: loss = 0.0745; FVE =  0.63 (0.021 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1044; FVE = 0.480\n",
      "r = 0.606\n",
      "More training!\n",
      "Step 15850: loss = 0.0671; FVE =  0.67 (0.025 sec)\n",
      "Step 15900: loss = 0.0783; FVE =  0.61 (0.021 sec)\n",
      "Step 15950: loss = 0.0814; FVE =  0.59 (0.021 sec)\n",
      "Step 16000: loss = 0.0831; FVE =  0.59 (0.021 sec)\n",
      "Step 16050: loss = 0.0731; FVE =  0.64 (0.023 sec)\n",
      "Step 16100: loss = 0.0742; FVE =  0.63 (0.020 sec)\n",
      "Step 16150: loss = 0.0765; FVE =  0.62 (0.035 sec)\n",
      "Step 16200: loss = 0.0808; FVE =  0.60 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1048; FVE = 0.478\n",
      "r = 0.607\n",
      "More training!\n",
      "Step 16250: loss = 0.0778; FVE =  0.61 (0.025 sec)\n",
      "Step 16300: loss = 0.0865; FVE =  0.57 (0.025 sec)\n",
      "Step 16350: loss = 0.0839; FVE =  0.58 (0.023 sec)\n",
      "Step 16400: loss = 0.0710; FVE =  0.65 (0.022 sec)\n",
      "Step 16450: loss = 0.0826; FVE =  0.59 (0.020 sec)\n",
      "Step 16500: loss = 0.0833; FVE =  0.58 (0.021 sec)\n",
      "Step 16550: loss = 0.0751; FVE =  0.63 (0.022 sec)\n",
      "Step 16600: loss = 0.0781; FVE =  0.61 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1036; FVE = 0.484\n",
      "r = 0.608\n",
      "More training!\n",
      "Step 16650: loss = 0.0888; FVE =  0.56 (0.024 sec)\n",
      "Step 16700: loss = 0.0772; FVE =  0.62 (0.027 sec)\n",
      "Step 16750: loss = 0.0743; FVE =  0.63 (0.044 sec)\n",
      "Step 16800: loss = 0.0824; FVE =  0.59 (0.024 sec)\n",
      "Step 16850: loss = 0.0808; FVE =  0.60 (0.021 sec)\n",
      "Step 16900: loss = 0.0822; FVE =  0.59 (0.024 sec)\n",
      "Step 16950: loss = 0.0797; FVE =  0.60 (0.025 sec)\n",
      "Step 17000: loss = 0.0760; FVE =  0.62 (0.021 sec)\n",
      "Step 17050: loss = 0.0767; FVE =  0.62 (0.020 sec)\n",
      "Step 17100: loss = 0.0734; FVE =  0.63 (0.021 sec)\n",
      "Step 17150: loss = 0.0794; FVE =  0.60 (0.021 sec)\n",
      "Step 17200: loss = 0.0700; FVE =  0.65 (0.021 sec)\n",
      "Step 17250: loss = 0.0890; FVE =  0.56 (0.025 sec)\n",
      "Step 17300: loss = 0.0804; FVE =  0.60 (0.023 sec)\n",
      "Step 17350: loss = 0.0735; FVE =  0.63 (0.039 sec)\n",
      "Step 17400: loss = 0.0791; FVE =  0.61 (0.022 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1032; FVE = 0.486\n",
      "r = 0.610\n",
      "More training!\n",
      "Step 17450: loss = 0.0743; FVE =  0.63 (0.023 sec)\n",
      "Step 17500: loss = 0.0758; FVE =  0.62 (0.022 sec)\n",
      "Step 17550: loss = 0.0780; FVE =  0.61 (0.023 sec)\n",
      "Step 17600: loss = 0.0734; FVE =  0.63 (0.021 sec)\n",
      "Step 17650: loss = 0.0778; FVE =  0.61 (0.026 sec)\n",
      "Step 17700: loss = 0.0811; FVE =  0.60 (0.020 sec)\n",
      "Step 17750: loss = 0.0788; FVE =  0.61 (0.020 sec)\n",
      "Step 17800: loss = 0.0842; FVE =  0.58 (0.023 sec)\n",
      "Step 17850: loss = 0.0725; FVE =  0.64 (0.023 sec)\n",
      "Step 17900: loss = 0.0791; FVE =  0.61 (0.025 sec)\n",
      "Step 17950: loss = 0.0729; FVE =  0.64 (0.039 sec)\n",
      "Step 18000: loss = 0.0801; FVE =  0.60 (0.025 sec)\n",
      "Step 18050: loss = 0.0806; FVE =  0.60 (0.024 sec)\n",
      "Step 18100: loss = 0.0755; FVE =  0.62 (0.021 sec)\n",
      "Step 18150: loss = 0.0668; FVE =  0.67 (0.025 sec)\n",
      "Step 18200: loss = 0.0732; FVE =  0.64 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1021; FVE = 0.491\n",
      "r = 0.612\n",
      "More training!\n",
      "Step 18250: loss = 0.0766; FVE =  0.62 (0.024 sec)\n",
      "Step 18300: loss = 0.0814; FVE =  0.59 (0.020 sec)\n",
      "Step 18350: loss = 0.0754; FVE =  0.62 (0.025 sec)\n",
      "Step 18400: loss = 0.0711; FVE =  0.65 (0.025 sec)\n",
      "Step 18450: loss = 0.0749; FVE =  0.63 (0.025 sec)\n",
      "Step 18500: loss = 0.0698; FVE =  0.65 (0.023 sec)\n",
      "Step 18550: loss = 0.0706; FVE =  0.65 (0.036 sec)\n",
      "Step 18600: loss = 0.0683; FVE =  0.66 (0.041 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1020; FVE = 0.492\n",
      "r = 0.612\n",
      "More training!\n",
      "Step 18650: loss = 0.0761; FVE =  0.62 (0.029 sec)\n",
      "Step 18700: loss = 0.0721; FVE =  0.64 (0.024 sec)\n",
      "Step 18750: loss = 0.0716; FVE =  0.64 (0.022 sec)\n",
      "Step 18800: loss = 0.0741; FVE =  0.63 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1016; FVE = 0.494\n",
      "r = 0.613\n",
      "More training!\n",
      "Step 18850: loss = 0.0711; FVE =  0.65 (0.024 sec)\n",
      "Step 18900: loss = 0.0752; FVE =  0.63 (0.023 sec)\n",
      "Step 18950: loss = 0.0794; FVE =  0.60 (0.021 sec)\n",
      "Step 19000: loss = 0.0768; FVE =  0.62 (0.024 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1021; FVE = 0.491\n",
      "r = 0.613\n",
      "More training!\n",
      "Step 19050: loss = 0.0703; FVE =  0.65 (0.025 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 19100: loss = 0.0675; FVE =  0.66 (0.025 sec)\n",
      "Step 19150: loss = 0.0675; FVE =  0.66 (0.034 sec)\n",
      "Step 19200: loss = 0.0723; FVE =  0.64 (0.025 sec)\n",
      "Step 19250: loss = 0.0700; FVE =  0.65 (0.025 sec)\n",
      "Step 19300: loss = 0.0705; FVE =  0.65 (0.024 sec)\n",
      "Step 19350: loss = 0.0621; FVE =  0.69 (0.024 sec)\n",
      "Step 19400: loss = 0.0700; FVE =  0.65 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1015; FVE = 0.494\n",
      "r = 0.614\n",
      "More training!\n",
      "Step 19450: loss = 0.0688; FVE =  0.66 (0.026 sec)\n",
      "Step 19500: loss = 0.0734; FVE =  0.63 (0.026 sec)\n",
      "Step 19550: loss = 0.0680; FVE =  0.66 (0.024 sec)\n",
      "Step 19600: loss = 0.0727; FVE =  0.64 (0.021 sec)\n",
      "Step 19650: loss = 0.0705; FVE =  0.65 (0.029 sec)\n",
      "Step 19700: loss = 0.0703; FVE =  0.65 (0.019 sec)\n",
      "Step 19750: loss = 0.0757; FVE =  0.62 (0.030 sec)\n",
      "Step 19800: loss = 0.0707; FVE =  0.65 (0.035 sec)\n",
      "Step 19850: loss = 0.0700; FVE =  0.65 (0.025 sec)\n",
      "Step 19900: loss = 0.0736; FVE =  0.63 (0.027 sec)\n",
      "Step 19950: loss = 0.0679; FVE =  0.66 (0.025 sec)\n",
      "Step 20000: loss = 0.0680; FVE =  0.66 (0.023 sec)\n",
      "Step 20050: loss = 0.0700; FVE =  0.65 (0.022 sec)\n",
      "Step 20100: loss = 0.0704; FVE =  0.65 (0.025 sec)\n",
      "Step 20150: loss = 0.0700; FVE =  0.65 (0.036 sec)\n",
      "Step 20200: loss = 0.0681; FVE =  0.66 (0.024 sec)\n",
      "Step 20250: loss = 0.0692; FVE =  0.66 (0.023 sec)\n",
      "Step 20300: loss = 0.0744; FVE =  0.63 (0.021 sec)\n",
      "Step 20350: loss = 0.0686; FVE =  0.66 (0.029 sec)\n",
      "Step 20400: loss = 0.0758; FVE =  0.62 (0.038 sec)\n",
      "Step 20450: loss = 0.0671; FVE =  0.67 (0.024 sec)\n",
      "Step 20500: loss = 0.0734; FVE =  0.63 (0.020 sec)\n",
      "Step 20550: loss = 0.0713; FVE =  0.64 (0.025 sec)\n",
      "Step 20600: loss = 0.0685; FVE =  0.66 (0.023 sec)\n",
      "Step 20650: loss = 0.0676; FVE =  0.66 (0.021 sec)\n",
      "Step 20700: loss = 0.0707; FVE =  0.65 (0.021 sec)\n",
      "Step 20750: loss = 0.0698; FVE =  0.65 (0.020 sec)\n",
      "Step 20800: loss = 0.0628; FVE =  0.69 (0.021 sec)\n",
      "Step 20850: loss = 0.0684; FVE =  0.66 (0.031 sec)\n",
      "Step 20900: loss = 0.0691; FVE =  0.66 (0.019 sec)\n",
      "Step 20950: loss = 0.0700; FVE =  0.65 (0.023 sec)\n",
      "Step 21000: loss = 0.0721; FVE =  0.64 (0.037 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1008; FVE = 0.498\n",
      "r = 0.616\n",
      "More training!\n",
      "Step 21050: loss = 0.0754; FVE =  0.62 (0.023 sec)\n",
      "Step 21100: loss = 0.0641; FVE =  0.68 (0.025 sec)\n",
      "Step 21150: loss = 0.0664; FVE =  0.67 (0.021 sec)\n",
      "Step 21200: loss = 0.0716; FVE =  0.64 (0.025 sec)\n",
      "Step 21250: loss = 0.0728; FVE =  0.64 (0.022 sec)\n",
      "Step 21300: loss = 0.0672; FVE =  0.67 (0.021 sec)\n",
      "Step 21350: loss = 0.0641; FVE =  0.68 (0.025 sec)\n",
      "Step 21400: loss = 0.0703; FVE =  0.65 (0.021 sec)\n",
      "Step 21450: loss = 0.0683; FVE =  0.66 (0.020 sec)\n",
      "Step 21500: loss = 0.0706; FVE =  0.65 (0.026 sec)\n",
      "Step 21550: loss = 0.0647; FVE =  0.68 (0.021 sec)\n",
      "Step 21600: loss = 0.0734; FVE =  0.63 (0.036 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1000; FVE = 0.502\n",
      "r = 0.617\n",
      "More training!\n",
      "Step 21650: loss = 0.0655; FVE =  0.67 (0.021 sec)\n",
      "Step 21700: loss = 0.0705; FVE =  0.65 (0.023 sec)\n",
      "Step 21750: loss = 0.0682; FVE =  0.66 (0.021 sec)\n",
      "Step 21800: loss = 0.0719; FVE =  0.64 (0.027 sec)\n",
      "Step 21850: loss = 0.0641; FVE =  0.68 (0.023 sec)\n",
      "Step 21900: loss = 0.0655; FVE =  0.67 (0.019 sec)\n",
      "Step 21950: loss = 0.0662; FVE =  0.67 (0.020 sec)\n",
      "Step 22000: loss = 0.0659; FVE =  0.67 (0.020 sec)\n",
      "Step 22050: loss = 0.0668; FVE =  0.67 (0.024 sec)\n",
      "Step 22100: loss = 0.0637; FVE =  0.68 (0.024 sec)\n",
      "Step 22150: loss = 0.0701; FVE =  0.65 (0.024 sec)\n",
      "Step 22200: loss = 0.0623; FVE =  0.69 (0.021 sec)\n",
      "Step 22250: loss = 0.0688; FVE =  0.66 (0.042 sec)\n",
      "Step 22300: loss = 0.0674; FVE =  0.66 (0.022 sec)\n",
      "Step 22350: loss = 0.0723; FVE =  0.64 (0.021 sec)\n",
      "Step 22400: loss = 0.0644; FVE =  0.68 (0.020 sec)\n",
      "Step 22450: loss = 0.0670; FVE =  0.67 (0.029 sec)\n",
      "Step 22500: loss = 0.0668; FVE =  0.67 (0.021 sec)\n",
      "Step 22550: loss = 0.0661; FVE =  0.67 (0.021 sec)\n",
      "Step 22600: loss = 0.0642; FVE =  0.68 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.1004; FVE = 0.500\n",
      "r = 0.619\n",
      "More training!\n",
      "Step 22650: loss = 0.0625; FVE =  0.69 (0.021 sec)\n",
      "Step 22700: loss = 0.0735; FVE =  0.63 (0.020 sec)\n",
      "Step 22750: loss = 0.0655; FVE =  0.67 (0.022 sec)\n",
      "Step 22800: loss = 0.0682; FVE =  0.66 (0.023 sec)\n",
      "Step 22850: loss = 0.0694; FVE =  0.65 (0.038 sec)\n",
      "Step 22900: loss = 0.0631; FVE =  0.69 (0.027 sec)\n",
      "Step 22950: loss = 0.0732; FVE =  0.64 (0.026 sec)\n",
      "Step 23000: loss = 0.0650; FVE =  0.68 (0.025 sec)\n",
      "Step 23050: loss = 0.0620; FVE =  0.69 (0.023 sec)\n",
      "Step 23100: loss = 0.0682; FVE =  0.66 (0.029 sec)\n",
      "Step 23150: loss = 0.0620; FVE =  0.69 (0.033 sec)\n",
      "Step 23200: loss = 0.0688; FVE =  0.66 (0.021 sec)\n",
      "Step 23250: loss = 0.0662; FVE =  0.67 (0.020 sec)\n",
      "Step 23300: loss = 0.0617; FVE =  0.69 (0.023 sec)\n",
      "Step 23350: loss = 0.0653; FVE =  0.67 (0.022 sec)\n",
      "Step 23400: loss = 0.0634; FVE =  0.68 (0.021 sec)\n",
      "Step 23450: loss = 0.0722; FVE =  0.64 (0.032 sec)\n",
      "Step 23500: loss = 0.0677; FVE =  0.66 (0.021 sec)\n",
      "Step 23550: loss = 0.0650; FVE =  0.68 (0.020 sec)\n",
      "Step 23600: loss = 0.0666; FVE =  0.67 (0.023 sec)\n",
      "Step 23650: loss = 0.0606; FVE =  0.70 (0.023 sec)\n",
      "Step 23700: loss = 0.0644; FVE =  0.68 (0.021 sec)\n",
      "Step 23750: loss = 0.0645; FVE =  0.68 (0.020 sec)\n",
      "Step 23800: loss = 0.0661; FVE =  0.67 (0.022 sec)\n",
      "Step 23850: loss = 0.0621; FVE =  0.69 (0.026 sec)\n",
      "Step 23900: loss = 0.0743; FVE =  0.63 (0.022 sec)\n",
      "Step 23950: loss = 0.0672; FVE =  0.67 (0.022 sec)\n",
      "Step 24000: loss = 0.0654; FVE =  0.67 (0.024 sec)\n",
      "Step 24050: loss = 0.0610; FVE =  0.70 (0.040 sec)\n",
      "Step 24100: loss = 0.0647; FVE =  0.68 (0.031 sec)\n",
      "Step 24150: loss = 0.0627; FVE =  0.69 (0.022 sec)\n",
      "Step 24200: loss = 0.0709; FVE =  0.65 (0.027 sec)\n",
      "Step 24250: loss = 0.0709; FVE =  0.65 (0.021 sec)\n",
      "Step 24300: loss = 0.0666; FVE =  0.67 (0.020 sec)\n",
      "Step 24350: loss = 0.0604; FVE =  0.70 (0.021 sec)\n",
      "Step 24400: loss = 0.0651; FVE =  0.68 (0.024 sec)\n",
      "Step 24450: loss = 0.0632; FVE =  0.68 (0.022 sec)\n",
      "Step 24500: loss = 0.0636; FVE =  0.68 (0.024 sec)\n",
      "Step 24550: loss = 0.0647; FVE =  0.68 (0.024 sec)\n",
      "Step 24600: loss = 0.0605; FVE =  0.70 (0.024 sec)\n",
      "Step 24650: loss = 0.0632; FVE =  0.68 (0.026 sec)\n",
      "Step 24700: loss = 0.0658; FVE =  0.67 (0.035 sec)\n",
      "Step 24750: loss = 0.0628; FVE =  0.69 (0.021 sec)\n",
      "Step 24800: loss = 0.0631; FVE =  0.69 (0.022 sec)\n",
      "Step 24850: loss = 0.0606; FVE =  0.70 (0.023 sec)\n",
      "Step 24900: loss = 0.0665; FVE =  0.67 (0.021 sec)\n",
      "Step 24950: loss = 0.0639; FVE =  0.68 (0.021 sec)\n",
      "Step 25000: loss = 0.0637; FVE =  0.68 (0.025 sec)\n",
      "Step 25050: loss = 0.0605; FVE =  0.70 (0.021 sec)\n",
      "Step 25100: loss = 0.0595; FVE =  0.70 (0.019 sec)\n",
      "Step 25150: loss = 0.0619; FVE =  0.69 (0.025 sec)\n",
      "Step 25200: loss = 0.0608; FVE =  0.70 (0.023 sec)\n",
      "Step 25250: loss = 0.0647; FVE =  0.68 (0.024 sec)\n",
      "Step 25300: loss = 0.0601; FVE =  0.70 (0.019 sec)\n",
      "Step 25350: loss = 0.0675; FVE =  0.66 (0.031 sec)\n",
      "Step 25400: loss = 0.0646; FVE =  0.68 (0.025 sec)\n",
      "Step 25450: loss = 0.0615; FVE =  0.69 (0.024 sec)\n",
      "Step 25500: loss = 0.0605; FVE =  0.70 (0.025 sec)\n",
      "Step 25550: loss = 0.0640; FVE =  0.68 (0.022 sec)\n",
      "Step 25600: loss = 0.0572; FVE =  0.72 (0.024 sec)\n",
      "Step 25650: loss = 0.0620; FVE =  0.69 (0.025 sec)\n",
      "Step 25700: loss = 0.0611; FVE =  0.70 (0.021 sec)\n",
      "Step 25750: loss = 0.0585; FVE =  0.71 (0.025 sec)\n",
      "Step 25800: loss = 0.0585; FVE =  0.71 (0.020 sec)\n",
      "Step 25850: loss = 0.0601; FVE =  0.70 (0.020 sec)\n",
      "Step 25900: loss = 0.0669; FVE =  0.67 (0.024 sec)\n",
      "Step 25950: loss = 0.0673; FVE =  0.66 (0.035 sec)\n",
      "Step 26000: loss = 0.0655; FVE =  0.67 (0.022 sec)\n",
      "Step 26050: loss = 0.0647; FVE =  0.68 (0.019 sec)\n",
      "Step 26100: loss = 0.0573; FVE =  0.71 (0.024 sec)\n",
      "Step 26150: loss = 0.0630; FVE =  0.69 (0.020 sec)\n",
      "Step 26200: loss = 0.0649; FVE =  0.68 (0.023 sec)\n",
      "Step 26250: loss = 0.0622; FVE =  0.69 (0.020 sec)\n",
      "Step 26300: loss = 0.0629; FVE =  0.69 (0.020 sec)\n",
      "Step 26350: loss = 0.0572; FVE =  0.72 (0.025 sec)\n",
      "Step 26400: loss = 0.0597; FVE =  0.70 (0.021 sec)\n",
      "Step 26450: loss = 0.0626; FVE =  0.69 (0.022 sec)\n",
      "Step 26500: loss = 0.0561; FVE =  0.72 (0.021 sec)\n",
      "Step 26550: loss = 0.0666; FVE =  0.67 (0.043 sec)\n",
      "Step 26600: loss = 0.0642; FVE =  0.68 (0.023 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.0991; FVE = 0.506\n",
      "r = 0.621\n",
      "More training!\n",
      "Step 26650: loss = 0.0627; FVE =  0.69 (0.025 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 26700: loss = 0.0591; FVE =  0.71 (0.025 sec)\n",
      "Step 26750: loss = 0.0604; FVE =  0.70 (0.024 sec)\n",
      "Step 26800: loss = 0.0594; FVE =  0.70 (0.022 sec)\n",
      "Step 26850: loss = 0.0624; FVE =  0.69 (0.021 sec)\n",
      "Step 26900: loss = 0.0600; FVE =  0.70 (0.019 sec)\n",
      "Step 26950: loss = 0.0634; FVE =  0.68 (0.023 sec)\n",
      "Step 27000: loss = 0.0550; FVE =  0.73 (0.026 sec)\n",
      "Step 27050: loss = 0.0591; FVE =  0.71 (0.027 sec)\n",
      "Step 27100: loss = 0.0625; FVE =  0.69 (0.024 sec)\n",
      "Step 27150: loss = 0.0661; FVE =  0.67 (0.026 sec)\n",
      "Step 27200: loss = 0.0625; FVE =  0.69 (0.028 sec)\n",
      "Step 27250: loss = 0.0610; FVE =  0.70 (0.021 sec)\n",
      "Step 27300: loss = 0.0686; FVE =  0.66 (0.022 sec)\n",
      "Step 27350: loss = 0.0631; FVE =  0.69 (0.021 sec)\n",
      "Step 27400: loss = 0.0571; FVE =  0.72 (0.030 sec)\n",
      "Step 27450: loss = 0.0643; FVE =  0.68 (0.023 sec)\n",
      "Step 27500: loss = 0.0609; FVE =  0.70 (0.022 sec)\n",
      "Step 27550: loss = 0.0589; FVE =  0.71 (0.033 sec)\n",
      "Step 27600: loss = 0.0599; FVE =  0.70 (0.021 sec)\n",
      "Step 27650: loss = 0.0623; FVE =  0.69 (0.023 sec)\n",
      "Step 27700: loss = 0.0651; FVE =  0.68 (0.023 sec)\n",
      "Step 27750: loss = 0.0632; FVE =  0.69 (0.026 sec)\n",
      "Step 27800: loss = 0.0659; FVE =  0.67 (0.043 sec)\n",
      "Step 27850: loss = 0.0662; FVE =  0.67 (0.025 sec)\n",
      "Step 27900: loss = 0.0573; FVE =  0.71 (0.023 sec)\n",
      "Step 27950: loss = 0.0596; FVE =  0.70 (0.026 sec)\n",
      "Step 28000: loss = 0.0615; FVE =  0.69 (0.020 sec)\n",
      "Step 28050: loss = 0.0616; FVE =  0.69 (0.020 sec)\n",
      "Step 28100: loss = 0.0613; FVE =  0.69 (0.027 sec)\n",
      "Step 28150: loss = 0.0553; FVE =  0.72 (0.023 sec)\n",
      "Step 28200: loss = 0.0589; FVE =  0.71 (0.023 sec)\n",
      "Step 28250: loss = 0.0580; FVE =  0.71 (0.024 sec)\n",
      "Step 28300: loss = 0.0594; FVE =  0.70 (0.024 sec)\n",
      "Step 28350: loss = 0.0622; FVE =  0.69 (0.020 sec)\n",
      "Step 28400: loss = 0.0529; FVE =  0.74 (0.042 sec)\n",
      "Step 28450: loss = 0.0627; FVE =  0.69 (0.021 sec)\n",
      "Step 28500: loss = 0.0607; FVE =  0.70 (0.024 sec)\n",
      "Step 28550: loss = 0.0541; FVE =  0.73 (0.021 sec)\n",
      "Step 28600: loss = 0.0577; FVE =  0.71 (0.024 sec)\n",
      "Step 28650: loss = 0.0563; FVE =  0.72 (0.022 sec)\n",
      "Step 28700: loss = 0.0561; FVE =  0.72 (0.026 sec)\n",
      "Step 28750: loss = 0.0555; FVE =  0.72 (0.022 sec)\n",
      "Step 28800: loss = 0.0563; FVE =  0.72 (0.021 sec)\n",
      "Step 28850: loss = 0.0552; FVE =  0.72 (0.019 sec)\n",
      "Step 28900: loss = 0.0603; FVE =  0.70 (0.028 sec)\n",
      "Step 28950: loss = 0.0656; FVE =  0.67 (0.020 sec)\n",
      "Step 29000: loss = 0.0600; FVE =  0.70 (0.033 sec)\n",
      "Step 29050: loss = 0.0625; FVE =  0.69 (0.028 sec)\n",
      "Step 29100: loss = 0.0643; FVE =  0.68 (0.024 sec)\n",
      "Step 29150: loss = 0.0582; FVE =  0.71 (0.022 sec)\n",
      "Step 29200: loss = 0.0652; FVE =  0.68 (0.024 sec)\n",
      "Step 29250: loss = 0.0541; FVE =  0.73 (0.020 sec)\n",
      "Step 29300: loss = 0.0581; FVE =  0.71 (0.023 sec)\n",
      "Step 29350: loss = 0.0585; FVE =  0.71 (0.024 sec)\n",
      "Step 29400: loss = 0.0591; FVE =  0.71 (0.022 sec)\n",
      "Step 29450: loss = 0.0615; FVE =  0.69 (0.025 sec)\n",
      "Step 29500: loss = 0.0562; FVE =  0.72 (0.022 sec)\n",
      "Step 29550: loss = 0.0629; FVE =  0.69 (0.024 sec)\n",
      "Step 29600: loss = 0.0610; FVE =  0.70 (0.022 sec)\n",
      "Step 29650: loss = 0.0601; FVE =  0.70 (0.035 sec)\n",
      "Step 29700: loss = 0.0577; FVE =  0.71 (0.021 sec)\n",
      "Step 29750: loss = 0.0592; FVE =  0.71 (0.020 sec)\n",
      "Step 29800: loss = 0.0593; FVE =  0.70 (0.021 sec)\n",
      "Step 29850: loss = 0.0615; FVE =  0.69 (0.024 sec)\n",
      "Step 29900: loss = 0.0577; FVE =  0.71 (0.033 sec)\n",
      "Step 29950: loss = 0.0621; FVE =  0.69 (0.023 sec)\n",
      "Step 30000: loss = 0.0539; FVE =  0.73 (0.022 sec)\n",
      "Step 30050: loss = 0.0570; FVE =  0.72 (0.020 sec)\n",
      "Step 30100: loss = 0.0592; FVE =  0.71 (0.022 sec)\n",
      "Step 30150: loss = 0.0560; FVE =  0.72 (0.024 sec)\n",
      "Step 30200: loss = 0.0563; FVE =  0.72 (0.022 sec)\n",
      "Step 30250: loss = 0.0568; FVE =  0.72 (0.034 sec)\n",
      "Step 30300: loss = 0.0568; FVE =  0.72 (0.021 sec)\n",
      "Step 30350: loss = 0.0566; FVE =  0.72 (0.024 sec)\n",
      "Step 30400: loss = 0.0639; FVE =  0.68 (0.025 sec)\n",
      "Step 30450: loss = 0.0562; FVE =  0.72 (0.023 sec)\n",
      "Step 30500: loss = 0.0567; FVE =  0.72 (0.022 sec)\n",
      "Step 30550: loss = 0.0566; FVE =  0.72 (0.023 sec)\n",
      "Step 30600: loss = 0.0595; FVE =  0.70 (0.020 sec)\n",
      "Step 30650: loss = 0.0592; FVE =  0.71 (0.024 sec)\n",
      "Step 30700: loss = 0.0552; FVE =  0.72 (0.021 sec)\n",
      "Step 30750: loss = 0.0580; FVE =  0.71 (0.023 sec)\n",
      "Step 30800: loss = 0.0577; FVE =  0.71 (0.025 sec)\n",
      "Step 30850: loss = 0.0597; FVE =  0.70 (0.038 sec)\n",
      "Step 30900: loss = 0.0519; FVE =  0.74 (0.032 sec)\n",
      "Step 30950: loss = 0.0602; FVE =  0.70 (0.022 sec)\n",
      "Step 31000: loss = 0.0591; FVE =  0.71 (0.022 sec)\n",
      "Step 31050: loss = 0.0539; FVE =  0.73 (0.025 sec)\n",
      "Step 31100: loss = 0.0592; FVE =  0.71 (0.026 sec)\n",
      "Step 31150: loss = 0.0578; FVE =  0.71 (0.024 sec)\n",
      "Step 31200: loss = 0.0554; FVE =  0.72 (0.023 sec)\n",
      "Step 31250: loss = 0.0521; FVE =  0.74 (0.021 sec)\n",
      "Step 31300: loss = 0.0639; FVE =  0.68 (0.024 sec)\n",
      "Step 31350: loss = 0.0593; FVE =  0.70 (0.023 sec)\n",
      "Step 31400: loss = 0.0532; FVE =  0.74 (0.022 sec)\n",
      "Step 31450: loss = 0.0528; FVE =  0.74 (0.022 sec)\n",
      "Step 31500: loss = 0.0606; FVE =  0.70 (0.032 sec)\n",
      "Step 31550: loss = 0.0580; FVE =  0.71 (0.024 sec)\n",
      "Step 31600: loss = 0.0586; FVE =  0.71 (0.022 sec)\n",
      "Step 31650: loss = 0.0526; FVE =  0.74 (0.025 sec)\n",
      "Step 31700: loss = 0.0605; FVE =  0.70 (0.028 sec)\n",
      "Step 31750: loss = 0.0539; FVE =  0.73 (0.023 sec)\n",
      "Step 31800: loss = 0.0522; FVE =  0.74 (0.026 sec)\n",
      "Step 31850: loss = 0.0574; FVE =  0.71 (0.021 sec)\n",
      "Step 31900: loss = 0.0632; FVE =  0.69 (0.025 sec)\n",
      "Step 31950: loss = 0.0570; FVE =  0.72 (0.023 sec)\n",
      "Step 32000: loss = 0.0553; FVE =  0.72 (0.027 sec)\n",
      "Step 32050: loss = 0.0522; FVE =  0.74 (0.021 sec)\n",
      "Step 32100: loss = 0.0517; FVE =  0.74 (0.040 sec)\n",
      "Step 32150: loss = 0.0542; FVE =  0.73 (0.023 sec)\n",
      "Step 32200: loss = 0.0597; FVE =  0.70 (0.026 sec)\n",
      "Step 32250: loss = 0.0525; FVE =  0.74 (0.021 sec)\n",
      "Step 32300: loss = 0.0546; FVE =  0.73 (0.021 sec)\n",
      "Step 32350: loss = 0.0554; FVE =  0.72 (0.033 sec)\n",
      "Step 32400: loss = 0.0518; FVE =  0.74 (0.027 sec)\n",
      "Step 32450: loss = 0.0584; FVE =  0.71 (0.023 sec)\n",
      "Step 32500: loss = 0.0541; FVE =  0.73 (0.021 sec)\n",
      "Step 32550: loss = 0.0480; FVE =  0.76 (0.023 sec)\n",
      "Step 32600: loss = 0.0571; FVE =  0.72 (0.022 sec)\n",
      "Step 32650: loss = 0.0531; FVE =  0.74 (0.026 sec)\n",
      "Step 32700: loss = 0.0646; FVE =  0.68 (0.032 sec)\n",
      "Step 32750: loss = 0.0549; FVE =  0.73 (0.042 sec)\n",
      "Step 32800: loss = 0.0575; FVE =  0.71 (0.029 sec)\n",
      "Step 32850: loss = 0.0518; FVE =  0.74 (0.020 sec)\n",
      "Step 32900: loss = 0.0587; FVE =  0.71 (0.027 sec)\n",
      "Step 32950: loss = 0.0577; FVE =  0.71 (0.023 sec)\n",
      "Step 33000: loss = 0.0497; FVE =  0.75 (0.021 sec)\n",
      "Step 33050: loss = 0.0579; FVE =  0.71 (0.021 sec)\n",
      "Step 33100: loss = 0.0589; FVE =  0.71 (0.022 sec)\n",
      "Step 33150: loss = 0.0546; FVE =  0.73 (0.020 sec)\n",
      "Step 33200: loss = 0.0573; FVE =  0.71 (0.025 sec)\n",
      "Step 33250: loss = 0.0535; FVE =  0.73 (0.022 sec)\n",
      "Step 33300: loss = 0.0515; FVE =  0.74 (0.025 sec)\n",
      "Step 33350: loss = 0.0570; FVE =  0.72 (0.042 sec)\n",
      "Step 33400: loss = 0.0585; FVE =  0.71 (0.025 sec)\n",
      "Step 33450: loss = 0.0575; FVE =  0.71 (0.019 sec)\n",
      "Step 33500: loss = 0.0542; FVE =  0.73 (0.021 sec)\n",
      "Step 33550: loss = 0.0571; FVE =  0.72 (0.024 sec)\n",
      "Step 33600: loss = 0.0513; FVE =  0.74 (0.023 sec)\n",
      "Step 33650: loss = 0.0541; FVE =  0.73 (0.021 sec)\n",
      "Step 33700: loss = 0.0564; FVE =  0.72 (0.026 sec)\n",
      "Step 33750: loss = 0.0572; FVE =  0.71 (0.023 sec)\n",
      "Step 33800: loss = 0.0504; FVE =  0.75 (0.021 sec)\n",
      "Step 33850: loss = 0.0593; FVE =  0.70 (0.019 sec)\n",
      "Step 33900: loss = 0.0556; FVE =  0.72 (0.021 sec)\n",
      "Step 33950: loss = 0.0539; FVE =  0.73 (0.032 sec)\n",
      "Step 34000: loss = 0.0559; FVE =  0.72 (0.026 sec)\n",
      "Step 34050: loss = 0.0537; FVE =  0.73 (0.025 sec)\n",
      "Step 34100: loss = 0.0583; FVE =  0.71 (0.026 sec)\n",
      "Step 34150: loss = 0.0520; FVE =  0.74 (0.028 sec)\n",
      "Step 34200: loss = 0.0607; FVE =  0.70 (0.028 sec)\n",
      "Step 34250: loss = 0.0519; FVE =  0.74 (0.022 sec)\n",
      "Step 34300: loss = 0.0545; FVE =  0.73 (0.021 sec)\n",
      "Step 34350: loss = 0.0561; FVE =  0.72 (0.023 sec)\n",
      "Step 34400: loss = 0.0487; FVE =  0.76 (0.023 sec)\n",
      "Step 34450: loss = 0.0577; FVE =  0.71 (0.024 sec)\n",
      "Step 34500: loss = 0.0568; FVE =  0.72 (0.022 sec)\n",
      "Step 34550: loss = 0.0575; FVE =  0.71 (0.038 sec)\n",
      "Step 34600: loss = 0.0562; FVE =  0.72 (0.040 sec)\n",
      "Step 34650: loss = 0.0578; FVE =  0.71 (0.024 sec)\n",
      "Step 34700: loss = 0.0545; FVE =  0.73 (0.023 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 34750: loss = 0.0534; FVE =  0.73 (0.024 sec)\n",
      "Step 34800: loss = 0.0537; FVE =  0.73 (0.024 sec)\n",
      "Step 34850: loss = 0.0500; FVE =  0.75 (0.022 sec)\n",
      "Step 34900: loss = 0.0527; FVE =  0.74 (0.025 sec)\n",
      "Step 34950: loss = 0.0581; FVE =  0.71 (0.022 sec)\n",
      "Step 35000: loss = 0.0535; FVE =  0.73 (0.026 sec)\n",
      "Step 35050: loss = 0.0540; FVE =  0.73 (0.023 sec)\n",
      "Step 35100: loss = 0.0510; FVE =  0.75 (0.026 sec)\n",
      "Step 35150: loss = 0.0541; FVE =  0.73 (0.028 sec)\n",
      "Step 35200: loss = 0.0475; FVE =  0.76 (0.043 sec)\n",
      "Step 35250: loss = 0.0563; FVE =  0.72 (0.022 sec)\n",
      "Step 35300: loss = 0.0525; FVE =  0.74 (0.023 sec)\n",
      "Step 35350: loss = 0.0542; FVE =  0.73 (0.022 sec)\n",
      "Step 35400: loss = 0.0558; FVE =  0.72 (0.021 sec)\n",
      "Step 35450: loss = 0.0538; FVE =  0.73 (0.028 sec)\n",
      "Step 35500: loss = 0.0508; FVE =  0.75 (0.026 sec)\n",
      "Step 35550: loss = 0.0490; FVE =  0.76 (0.023 sec)\n",
      "Step 35600: loss = 0.0518; FVE =  0.74 (0.025 sec)\n",
      "Step 35650: loss = 0.0527; FVE =  0.74 (0.026 sec)\n",
      "Step 35700: loss = 0.0534; FVE =  0.73 (0.021 sec)\n",
      "Step 35750: loss = 0.0534; FVE =  0.73 (0.023 sec)\n",
      "Step 35800: loss = 0.0550; FVE =  0.73 (0.044 sec)\n",
      "Step 35850: loss = 0.0523; FVE =  0.74 (0.023 sec)\n",
      "Step 35900: loss = 0.0533; FVE =  0.73 (0.025 sec)\n",
      "Step 35950: loss = 0.0564; FVE =  0.72 (0.022 sec)\n",
      "Step 36000: loss = 0.0507; FVE =  0.75 (0.026 sec)\n",
      "Step 36050: loss = 0.0493; FVE =  0.75 (0.024 sec)\n",
      "Step 36100: loss = 0.0568; FVE =  0.72 (0.025 sec)\n",
      "Step 36150: loss = 0.0516; FVE =  0.74 (0.024 sec)\n",
      "Step 36200: loss = 0.0527; FVE =  0.74 (0.025 sec)\n",
      "Step 36250: loss = 0.0540; FVE =  0.73 (0.023 sec)\n",
      "Step 36300: loss = 0.0532; FVE =  0.74 (0.023 sec)\n",
      "Step 36350: loss = 0.0518; FVE =  0.74 (0.023 sec)\n",
      "Step 36400: loss = 0.0486; FVE =  0.76 (0.022 sec)\n",
      "Step 36450: loss = 0.0540; FVE =  0.73 (0.030 sec)\n",
      "Step 36500: loss = 0.0569; FVE =  0.72 (0.021 sec)\n",
      "Step 36550: loss = 0.0535; FVE =  0.73 (0.021 sec)\n",
      "Step 36600: loss = 0.0540; FVE =  0.73 (0.025 sec)\n",
      "early stop\n",
      "Performance is:\n",
      "squared (loss) = 0.0973; FVE = 0.515\n",
      "r = 0.625\n",
      "More training!\n",
      "Step 36650: loss = 0.0509; FVE =  0.75 (0.021 sec)\n",
      "Step 36700: loss = 0.0486; FVE =  0.76 (0.020 sec)\n",
      "Step 36750: loss = 0.0492; FVE =  0.76 (0.025 sec)\n",
      "Step 36800: loss = 0.0546; FVE =  0.73 (0.022 sec)\n",
      "Step 36850: loss = 0.0535; FVE =  0.73 (0.024 sec)\n",
      "Step 36900: loss = 0.0528; FVE =  0.74 (0.023 sec)\n",
      "Step 36950: loss = 0.0509; FVE =  0.75 (0.024 sec)\n",
      "Step 37000: loss = 0.0527; FVE =  0.74 (0.025 sec)\n",
      "Step 37050: loss = 0.0533; FVE =  0.73 (0.035 sec)\n",
      "Step 37100: loss = 0.0542; FVE =  0.73 (0.023 sec)\n",
      "Step 37150: loss = 0.0501; FVE =  0.75 (0.023 sec)\n",
      "Step 37200: loss = 0.0550; FVE =  0.73 (0.023 sec)\n",
      "Step 37250: loss = 0.0536; FVE =  0.73 (0.023 sec)\n",
      "Step 37300: loss = 0.0499; FVE =  0.75 (0.022 sec)\n",
      "Step 37350: loss = 0.0528; FVE =  0.74 (0.031 sec)\n",
      "Step 37400: loss = 0.0503; FVE =  0.75 (0.021 sec)\n",
      "Step 37450: loss = 0.0546; FVE =  0.73 (0.023 sec)\n",
      "Step 37500: loss = 0.0515; FVE =  0.74 (0.022 sec)\n",
      "Step 37550: loss = 0.0530; FVE =  0.74 (0.022 sec)\n",
      "Step 37600: loss = 0.0516; FVE =  0.74 (0.023 sec)\n",
      "Step 37650: loss = 0.0501; FVE =  0.75 (0.036 sec)\n",
      "Step 37700: loss = 0.0523; FVE =  0.74 (0.044 sec)\n",
      "Step 37750: loss = 0.0520; FVE =  0.74 (0.021 sec)\n",
      "Step 37800: loss = 0.0500; FVE =  0.75 (0.022 sec)\n",
      "Step 37850: loss = 0.0538; FVE =  0.73 (0.024 sec)\n",
      "Step 37900: loss = 0.0497; FVE =  0.75 (0.023 sec)\n",
      "Step 37950: loss = 0.0589; FVE =  0.71 (0.021 sec)\n",
      "Step 38000: loss = 0.0451; FVE =  0.78 (0.024 sec)\n",
      "Step 38050: loss = 0.0530; FVE =  0.74 (0.021 sec)\n",
      "Step 38100: loss = 0.0517; FVE =  0.74 (0.025 sec)\n",
      "Step 38150: loss = 0.0557; FVE =  0.72 (0.025 sec)\n",
      "Step 38200: loss = 0.0510; FVE =  0.75 (0.023 sec)\n",
      "Step 38250: loss = 0.0457; FVE =  0.77 (0.021 sec)\n",
      "Step 38300: loss = 0.0489; FVE =  0.76 (0.034 sec)\n",
      "Step 38350: loss = 0.0532; FVE =  0.73 (0.020 sec)\n",
      "Step 38400: loss = 0.0544; FVE =  0.73 (0.020 sec)\n",
      "Step 38450: loss = 0.0487; FVE =  0.76 (0.025 sec)\n",
      "Step 38500: loss = 0.0521; FVE =  0.74 (0.023 sec)\n",
      "Step 38550: loss = 0.0550; FVE =  0.73 (0.025 sec)\n",
      "Step 38600: loss = 0.0537; FVE =  0.73 (0.024 sec)\n",
      "Step 38650: loss = 0.0490; FVE =  0.76 (0.025 sec)\n",
      "Step 38700: loss = 0.0551; FVE =  0.73 (0.022 sec)\n",
      "Step 38750: loss = 0.0502; FVE =  0.75 (0.023 sec)\n",
      "Step 38800: loss = 0.0532; FVE =  0.73 (0.025 sec)\n",
      "Step 38850: loss = 0.0512; FVE =  0.74 (0.023 sec)\n",
      "Step 38900: loss = 0.0539; FVE =  0.73 (0.040 sec)\n",
      "Step 38950: loss = 0.0514; FVE =  0.74 (0.028 sec)\n",
      "Step 39000: loss = 0.0453; FVE =  0.77 (0.039 sec)\n",
      "Step 39050: loss = 0.0469; FVE =  0.77 (0.021 sec)\n",
      "Step 39100: loss = 0.0506; FVE =  0.75 (0.024 sec)\n",
      "Step 39150: loss = 0.0512; FVE =  0.74 (0.021 sec)\n",
      "Step 39200: loss = 0.0520; FVE =  0.74 (0.022 sec)\n",
      "Step 39250: loss = 0.0521; FVE =  0.74 (0.039 sec)\n",
      "Step 39300: loss = 0.0481; FVE =  0.76 (0.043 sec)\n",
      "Step 39350: loss = 0.0496; FVE =  0.75 (0.026 sec)\n",
      "Step 39400: loss = 0.0531; FVE =  0.74 (0.022 sec)\n",
      "Step 39450: loss = 0.0550; FVE =  0.73 (0.043 sec)\n",
      "Step 39500: loss = 0.0519; FVE =  0.74 (0.025 sec)\n",
      "Step 39550: loss = 0.0492; FVE =  0.75 (0.042 sec)\n",
      "Step 39600: loss = 0.0530; FVE =  0.74 (0.061 sec)\n",
      "Step 39650: loss = 0.0490; FVE =  0.76 (0.031 sec)\n",
      "Step 39700: loss = 0.0505; FVE =  0.75 (0.021 sec)\n",
      "Step 39750: loss = 0.0496; FVE =  0.75 (0.045 sec)\n",
      "Step 39800: loss = 0.0525; FVE =  0.74 (0.054 sec)\n",
      "Step 39850: loss = 0.0491; FVE =  0.76 (0.070 sec)\n",
      "Step 39900: loss = 0.0501; FVE =  0.75 (0.046 sec)\n",
      "Step 39950: loss = 0.0499; FVE =  0.75 (0.025 sec)\n",
      "Step 40000: loss = 0.0478; FVE =  0.76 (0.029 sec)\n",
      "Step 40050: loss = 0.0530; FVE =  0.74 (0.022 sec)\n",
      "Step 40100: loss = 0.0493; FVE =  0.75 (0.023 sec)\n",
      "Step 40150: loss = 0.0548; FVE =  0.73 (0.036 sec)\n",
      "Step 40200: loss = 0.0521; FVE =  0.74 (0.024 sec)\n",
      "Step 40250: loss = 0.0478; FVE =  0.76 (0.061 sec)\n",
      "Step 40300: loss = 0.0486; FVE =  0.76 (0.049 sec)\n",
      "Step 40350: loss = 0.0482; FVE =  0.76 (0.044 sec)\n",
      "Step 40400: loss = 0.0528; FVE =  0.74 (0.057 sec)\n",
      "Step 40450: loss = 0.0525; FVE =  0.74 (0.022 sec)\n",
      "Step 40500: loss = 0.0516; FVE =  0.74 (0.021 sec)\n",
      "Step 40550: loss = 0.0458; FVE =  0.77 (0.038 sec)\n",
      "Step 40600: loss = 0.0556; FVE =  0.72 (0.028 sec)\n",
      "Step 40650: loss = 0.0443; FVE =  0.78 (0.035 sec)\n",
      "Step 40700: loss = 0.0477; FVE =  0.76 (0.027 sec)\n",
      "Step 40750: loss = 0.0464; FVE =  0.77 (0.020 sec)\n",
      "Step 40800: loss = 0.0507; FVE =  0.75 (0.025 sec)\n",
      "Step 40850: loss = 0.0542; FVE =  0.73 (0.020 sec)\n",
      "Step 40900: loss = 0.0507; FVE =  0.75 (0.021 sec)\n",
      "Step 40950: loss = 0.0518; FVE =  0.74 (0.021 sec)\n",
      "Step 41000: loss = 0.0474; FVE =  0.76 (0.025 sec)\n",
      "Step 41050: loss = 0.0507; FVE =  0.75 (0.024 sec)\n",
      "Step 41100: loss = 0.0508; FVE =  0.75 (0.022 sec)\n",
      "Step 41150: loss = 0.0414; FVE =  0.79 (0.022 sec)\n",
      "Step 41200: loss = 0.0494; FVE =  0.75 (0.024 sec)\n",
      "Step 41250: loss = 0.0488; FVE =  0.76 (0.035 sec)\n",
      "Step 41300: loss = 0.0516; FVE =  0.74 (0.023 sec)\n",
      "Step 41350: loss = 0.0472; FVE =  0.76 (0.021 sec)\n",
      "Step 41400: loss = 0.0461; FVE =  0.77 (0.021 sec)\n",
      "Step 41450: loss = 0.0503; FVE =  0.75 (0.024 sec)\n",
      "Step 41500: loss = 0.0517; FVE =  0.74 (0.020 sec)\n",
      "Step 41550: loss = 0.0506; FVE =  0.75 (0.031 sec)\n",
      "Step 41600: loss = 0.0467; FVE =  0.77 (0.034 sec)\n",
      "Step 41650: loss = 0.0460; FVE =  0.77 (0.033 sec)\n",
      "Step 41700: loss = 0.0595; FVE =  0.70 (0.027 sec)\n",
      "Step 41750: loss = 0.0502; FVE =  0.75 (0.032 sec)\n",
      "Step 41800: loss = 0.0486; FVE =  0.76 (0.039 sec)\n",
      "Step 41850: loss = 0.0513; FVE =  0.74 (0.029 sec)\n",
      "Step 41900: loss = 0.0464; FVE =  0.77 (0.025 sec)\n",
      "Step 41950: loss = 0.0475; FVE =  0.76 (0.023 sec)\n",
      "Step 42000: loss = 0.0491; FVE =  0.76 (0.023 sec)\n",
      "Step 42050: loss = 0.0480; FVE =  0.76 (0.023 sec)\n",
      "Step 42100: loss = 0.0478; FVE =  0.76 (0.021 sec)\n",
      "Step 42150: loss = 0.0545; FVE =  0.73 (0.022 sec)\n",
      "Step 42200: loss = 0.0487; FVE =  0.76 (0.022 sec)\n",
      "Step 42250: loss = 0.0481; FVE =  0.76 (0.020 sec)\n",
      "Step 42300: loss = 0.0479; FVE =  0.76 (0.028 sec)\n",
      "Step 42350: loss = 0.0471; FVE =  0.77 (0.038 sec)\n",
      "Step 42400: loss = 0.0512; FVE =  0.74 (0.020 sec)\n",
      "Step 42450: loss = 0.0479; FVE =  0.76 (0.022 sec)\n",
      "Step 42500: loss = 0.0465; FVE =  0.77 (0.021 sec)\n",
      "Step 42550: loss = 0.0523; FVE =  0.74 (0.022 sec)\n",
      "Step 42600: loss = 0.0465; FVE =  0.77 (0.029 sec)\n",
      "Step 42650: loss = 0.0484; FVE =  0.76 (0.024 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 42700: loss = 0.0475; FVE =  0.76 (0.021 sec)\n",
      "Step 42750: loss = 0.0471; FVE =  0.77 (0.022 sec)\n",
      "Step 42800: loss = 0.0494; FVE =  0.75 (0.023 sec)\n",
      "Step 42850: loss = 0.0459; FVE =  0.77 (0.023 sec)\n",
      "Step 42900: loss = 0.0480; FVE =  0.76 (0.021 sec)\n",
      "Step 42950: loss = 0.0479; FVE =  0.76 (0.038 sec)\n",
      "Step 43000: loss = 0.0500; FVE =  0.75 (0.022 sec)\n",
      "Step 43050: loss = 0.0545; FVE =  0.73 (0.023 sec)\n",
      "Step 43100: loss = 0.0467; FVE =  0.77 (0.022 sec)\n",
      "Step 43150: loss = 0.0500; FVE =  0.75 (0.021 sec)\n",
      "Step 43200: loss = 0.0506; FVE =  0.75 (0.021 sec)\n",
      "Step 43250: loss = 0.0495; FVE =  0.75 (0.021 sec)\n",
      "Step 43300: loss = 0.0467; FVE =  0.77 (0.021 sec)\n",
      "Step 43350: loss = 0.0486; FVE =  0.76 (0.022 sec)\n",
      "Step 43400: loss = 0.0513; FVE =  0.74 (0.022 sec)\n",
      "Step 43450: loss = 0.0463; FVE =  0.77 (0.020 sec)\n",
      "Step 43500: loss = 0.0468; FVE =  0.77 (0.021 sec)\n",
      "Step 43550: loss = 0.0510; FVE =  0.75 (0.037 sec)\n",
      "Step 43600: loss = 0.0470; FVE =  0.77 (0.021 sec)\n",
      "Step 43650: loss = 0.0446; FVE =  0.78 (0.025 sec)\n",
      "Step 43700: loss = 0.0440; FVE =  0.78 (0.023 sec)\n",
      "Step 43750: loss = 0.0479; FVE =  0.76 (0.024 sec)\n",
      "Step 43800: loss = 0.0441; FVE =  0.78 (0.026 sec)\n",
      "Step 43850: loss = 0.0444; FVE =  0.78 (0.021 sec)\n",
      "Step 43900: loss = 0.0461; FVE =  0.77 (0.031 sec)\n",
      "Step 43950: loss = 0.0494; FVE =  0.75 (0.021 sec)\n",
      "Step 44000: loss = 0.0464; FVE =  0.77 (0.020 sec)\n",
      "Step 44050: loss = 0.0494; FVE =  0.75 (0.023 sec)\n",
      "Step 44100: loss = 0.0444; FVE =  0.78 (0.021 sec)\n",
      "Step 44150: loss = 0.0478; FVE =  0.76 (0.028 sec)\n",
      "Step 44200: loss = 0.0519; FVE =  0.74 (0.042 sec)\n",
      "Step 44250: loss = 0.0513; FVE =  0.74 (0.022 sec)\n",
      "Step 44300: loss = 0.0523; FVE =  0.74 (0.021 sec)\n",
      "Step 44350: loss = 0.0439; FVE =  0.78 (0.026 sec)\n",
      "Step 44400: loss = 0.0481; FVE =  0.76 (0.025 sec)\n",
      "Step 44450: loss = 0.0477; FVE =  0.76 (0.027 sec)\n",
      "Step 44500: loss = 0.0500; FVE =  0.75 (0.023 sec)\n",
      "Step 44550: loss = 0.0469; FVE =  0.77 (0.022 sec)\n",
      "Step 44600: loss = 0.0460; FVE =  0.77 (0.022 sec)\n",
      "Step 44650: loss = 0.0468; FVE =  0.77 (0.025 sec)\n",
      "Step 44700: loss = 0.0479; FVE =  0.76 (0.021 sec)\n",
      "Step 44750: loss = 0.0437; FVE =  0.78 (0.025 sec)\n",
      "Step 44800: loss = 0.0431; FVE =  0.79 (0.033 sec)\n",
      "Step 44850: loss = 0.0476; FVE =  0.76 (0.022 sec)\n",
      "Step 44900: loss = 0.0454; FVE =  0.77 (0.021 sec)\n",
      "Step 44950: loss = 0.0512; FVE =  0.75 (0.023 sec)\n",
      "Step 45000: loss = 0.0451; FVE =  0.78 (0.027 sec)\n",
      "Step 45050: loss = 0.0468; FVE =  0.77 (0.024 sec)\n",
      "Step 45100: loss = 0.0485; FVE =  0.76 (0.020 sec)\n",
      "Step 45150: loss = 0.0495; FVE =  0.75 (0.024 sec)\n",
      "Step 45200: loss = 0.0496; FVE =  0.75 (0.022 sec)\n",
      "Step 45250: loss = 0.0511; FVE =  0.75 (0.022 sec)\n",
      "Step 45300: loss = 0.0487; FVE =  0.76 (0.024 sec)\n",
      "Step 45350: loss = 0.0504; FVE =  0.75 (0.025 sec)\n",
      "Step 45400: loss = 0.0445; FVE =  0.78 (0.038 sec)\n",
      "Step 45450: loss = 0.0469; FVE =  0.77 (0.022 sec)\n",
      "Step 45500: loss = 0.0506; FVE =  0.75 (0.021 sec)\n",
      "Step 45550: loss = 0.0503; FVE =  0.75 (0.024 sec)\n",
      "Step 45600: loss = 0.0475; FVE =  0.76 (0.023 sec)\n",
      "Step 45650: loss = 0.0475; FVE =  0.76 (0.020 sec)\n",
      "Step 45700: loss = 0.0451; FVE =  0.78 (0.023 sec)\n",
      "Step 45750: loss = 0.0499; FVE =  0.75 (0.025 sec)\n",
      "Step 45800: loss = 0.0466; FVE =  0.77 (0.022 sec)\n",
      "Step 45850: loss = 0.0484; FVE =  0.76 (0.022 sec)\n",
      "Step 45900: loss = 0.0467; FVE =  0.77 (0.022 sec)\n",
      "Step 45950: loss = 0.0470; FVE =  0.77 (0.022 sec)\n",
      "Step 46000: loss = 0.0435; FVE =  0.78 (0.035 sec)\n",
      "Step 46050: loss = 0.0467; FVE =  0.77 (0.023 sec)\n",
      "Step 46100: loss = 0.0471; FVE =  0.77 (0.022 sec)\n",
      "Step 46150: loss = 0.0468; FVE =  0.77 (0.024 sec)\n",
      "Step 46200: loss = 0.0547; FVE =  0.73 (0.023 sec)\n",
      "Step 46250: loss = 0.0468; FVE =  0.77 (0.026 sec)\n",
      "Step 46300: loss = 0.0479; FVE =  0.76 (0.021 sec)\n",
      "Step 46350: loss = 0.0468; FVE =  0.77 (0.027 sec)\n",
      "Step 46400: loss = 0.0460; FVE =  0.77 (0.021 sec)\n",
      "Step 46450: loss = 0.0474; FVE =  0.76 (0.020 sec)\n",
      "Step 46500: loss = 0.0441; FVE =  0.78 (0.021 sec)\n",
      "Step 46550: loss = 0.0446; FVE =  0.78 (0.021 sec)\n",
      "Step 46600: loss = 0.0422; FVE =  0.79 (0.022 sec)\n",
      "Step 46650: loss = 0.0450; FVE =  0.78 (0.036 sec)\n",
      "Step 46700: loss = 0.0450; FVE =  0.78 (0.022 sec)\n",
      "Step 46750: loss = 0.0492; FVE =  0.75 (0.026 sec)\n",
      "Step 46800: loss = 0.0496; FVE =  0.75 (0.021 sec)\n",
      "Step 46850: loss = 0.0457; FVE =  0.77 (0.026 sec)\n",
      "Step 46900: loss = 0.0476; FVE =  0.76 (0.023 sec)\n",
      "Step 46950: loss = 0.0479; FVE =  0.76 (0.022 sec)\n",
      "Step 47000: loss = 0.0480; FVE =  0.76 (0.023 sec)\n",
      "Step 47050: loss = 0.0456; FVE =  0.77 (0.051 sec)\n",
      "Step 47100: loss = 0.0448; FVE =  0.78 (0.024 sec)\n",
      "Step 47150: loss = 0.0453; FVE =  0.77 (0.035 sec)\n",
      "Step 47200: loss = 0.0525; FVE =  0.74 (0.027 sec)\n",
      "Step 47250: loss = 0.0442; FVE =  0.78 (0.026 sec)\n",
      "Step 47300: loss = 0.0445; FVE =  0.78 (0.032 sec)\n",
      "Step 47350: loss = 0.0436; FVE =  0.78 (0.021 sec)\n",
      "Step 47400: loss = 0.0490; FVE =  0.76 (0.020 sec)\n",
      "Step 47450: loss = 0.0459; FVE =  0.77 (0.034 sec)\n",
      "Step 47500: loss = 0.0485; FVE =  0.76 (0.024 sec)\n",
      "Step 47550: loss = 0.0473; FVE =  0.76 (0.021 sec)\n",
      "Step 47600: loss = 0.0457; FVE =  0.77 (0.021 sec)\n",
      "Step 47650: loss = 0.0449; FVE =  0.78 (0.023 sec)\n",
      "Step 47700: loss = 0.0457; FVE =  0.77 (0.028 sec)\n",
      "Step 47750: loss = 0.0471; FVE =  0.77 (0.025 sec)\n",
      "Step 47800: loss = 0.0451; FVE =  0.78 (0.035 sec)\n",
      "Step 47850: loss = 0.0523; FVE =  0.74 (0.028 sec)\n",
      "Step 47900: loss = 0.0489; FVE =  0.76 (0.024 sec)\n",
      "Step 47950: loss = 0.0474; FVE =  0.76 (0.022 sec)\n",
      "Step 48000: loss = 0.0467; FVE =  0.77 (0.024 sec)\n",
      "Step 48050: loss = 0.0448; FVE =  0.78 (0.025 sec)\n",
      "Step 48100: loss = 0.0438; FVE =  0.78 (0.025 sec)\n",
      "Step 48150: loss = 0.0496; FVE =  0.75 (0.019 sec)\n",
      "Step 48200: loss = 0.0485; FVE =  0.76 (0.030 sec)\n",
      "Step 48250: loss = 0.0461; FVE =  0.77 (0.043 sec)\n",
      "Step 48300: loss = 0.0447; FVE =  0.78 (0.033 sec)\n",
      "Step 48350: loss = 0.0509; FVE =  0.75 (0.021 sec)\n",
      "Step 48400: loss = 0.0473; FVE =  0.76 (0.023 sec)\n",
      "Step 48450: loss = 0.0471; FVE =  0.77 (0.026 sec)\n",
      "Step 48500: loss = 0.0495; FVE =  0.75 (0.022 sec)\n",
      "Step 48550: loss = 0.0465; FVE =  0.77 (0.023 sec)\n",
      "Step 48600: loss = 0.0467; FVE =  0.77 (0.030 sec)\n",
      "Step 48650: loss = 0.0435; FVE =  0.78 (0.022 sec)\n",
      "Step 48700: loss = 0.0450; FVE =  0.78 (0.021 sec)\n",
      "Step 48750: loss = 0.0441; FVE =  0.78 (0.023 sec)\n",
      "Step 48800: loss = 0.0443; FVE =  0.78 (0.022 sec)\n",
      "Step 48850: loss = 0.0431; FVE =  0.79 (0.039 sec)\n",
      "Step 48900: loss = 0.0436; FVE =  0.78 (0.021 sec)\n",
      "Step 48950: loss = 0.0447; FVE =  0.78 (0.022 sec)\n",
      "Step 49000: loss = 0.0460; FVE =  0.77 (0.024 sec)\n",
      "Step 49050: loss = 0.0414; FVE =  0.79 (0.021 sec)\n",
      "Step 49100: loss = 0.0453; FVE =  0.77 (0.021 sec)\n",
      "Step 49150: loss = 0.0481; FVE =  0.76 (0.019 sec)\n",
      "Step 49200: loss = 0.0463; FVE =  0.77 (0.020 sec)\n",
      "Step 49250: loss = 0.0460; FVE =  0.77 (0.019 sec)\n",
      "Step 49300: loss = 0.0488; FVE =  0.76 (0.022 sec)\n",
      "Step 49350: loss = 0.0494; FVE =  0.75 (0.022 sec)\n",
      "Step 49400: loss = 0.0459; FVE =  0.77 (0.020 sec)\n",
      "Step 49450: loss = 0.0426; FVE =  0.79 (0.041 sec)\n",
      "Step 49500: loss = 0.0414; FVE =  0.79 (0.021 sec)\n",
      "Step 49550: loss = 0.0422; FVE =  0.79 (0.024 sec)\n",
      "Step 49600: loss = 0.0486; FVE =  0.76 (0.025 sec)\n",
      "Step 49650: loss = 0.0452; FVE =  0.77 (0.020 sec)\n",
      "Step 49700: loss = 0.0436; FVE =  0.78 (0.022 sec)\n",
      "Step 49750: loss = 0.0445; FVE =  0.78 (0.022 sec)\n",
      "Step 49800: loss = 0.0466; FVE =  0.77 (0.025 sec)\n",
      "Step 49850: loss = 0.0441; FVE =  0.78 (0.022 sec)\n",
      "Step 49900: loss = 0.0506; FVE =  0.75 (0.022 sec)\n",
      "Step 49950: loss = 0.0457; FVE =  0.77 (0.022 sec)\n",
      "Step 50000: loss = 0.0459; FVE =  0.77 (0.021 sec)\n",
      "Step 50050: loss = 0.0428; FVE =  0.79 (0.036 sec)\n",
      "Step 50100: loss = 0.0477; FVE =  0.76 (0.022 sec)\n",
      "Step 50150: loss = 0.0464; FVE =  0.77 (0.021 sec)\n",
      "Step 50200: loss = 0.0412; FVE =  0.79 (0.022 sec)\n",
      "Step 50250: loss = 0.0441; FVE =  0.78 (0.021 sec)\n",
      "Step 50300: loss = 0.0444; FVE =  0.78 (0.025 sec)\n",
      "Step 50350: loss = 0.0430; FVE =  0.79 (0.026 sec)\n",
      "Step 50400: loss = 0.0443; FVE =  0.78 (0.022 sec)\n",
      "Step 50450: loss = 0.0460; FVE =  0.77 (0.027 sec)\n",
      "Step 50500: loss = 0.0401; FVE =  0.80 (0.022 sec)\n",
      "Step 50550: loss = 0.0424; FVE =  0.79 (0.023 sec)\n",
      "Step 50600: loss = 0.0419; FVE =  0.79 (0.029 sec)\n",
      "Step 50650: loss = 0.0470; FVE =  0.77 (0.042 sec)\n",
      "Step 50700: loss = 0.0430; FVE =  0.79 (0.023 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50750: loss = 0.0449; FVE =  0.78 (0.022 sec)\n",
      "Step 50800: loss = 0.0469; FVE =  0.77 (0.023 sec)\n",
      "Step 50850: loss = 0.0460; FVE =  0.77 (0.021 sec)\n",
      "Step 50900: loss = 0.0473; FVE =  0.76 (0.020 sec)\n",
      "Step 50950: loss = 0.0432; FVE =  0.78 (0.025 sec)\n",
      "Step 51000: loss = 0.0506; FVE =  0.75 (0.020 sec)\n",
      "Step 51050: loss = 0.0421; FVE =  0.79 (0.022 sec)\n",
      "Step 51100: loss = 0.0459; FVE =  0.77 (0.020 sec)\n",
      "Step 51150: loss = 0.0448; FVE =  0.78 (0.023 sec)\n",
      "Step 51200: loss = 0.0423; FVE =  0.79 (0.023 sec)\n",
      "Step 51250: loss = 0.0450; FVE =  0.78 (0.041 sec)\n",
      "Step 51300: loss = 0.0413; FVE =  0.79 (0.045 sec)\n",
      "Step 51350: loss = 0.0469; FVE =  0.77 (0.021 sec)\n",
      "Step 51400: loss = 0.0457; FVE =  0.77 (0.024 sec)\n",
      "Step 51450: loss = 0.0434; FVE =  0.78 (0.021 sec)\n",
      "Step 51500: loss = 0.0497; FVE =  0.75 (0.022 sec)\n",
      "Step 51550: loss = 0.0429; FVE =  0.79 (0.021 sec)\n",
      "Step 51600: loss = 0.0451; FVE =  0.78 (0.024 sec)\n",
      "Step 51650: loss = 0.0466; FVE =  0.77 (0.027 sec)\n",
      "Step 51700: loss = 0.0405; FVE =  0.80 (0.024 sec)\n",
      "Step 51750: loss = 0.0430; FVE =  0.79 (0.021 sec)\n",
      "Step 51800: loss = 0.0491; FVE =  0.76 (0.021 sec)\n",
      "Step 51850: loss = 0.0411; FVE =  0.80 (0.022 sec)\n",
      "Step 51900: loss = 0.0438; FVE =  0.78 (0.037 sec)\n",
      "Step 51950: loss = 0.0459; FVE =  0.77 (0.024 sec)\n",
      "Step 52000: loss = 0.0453; FVE =  0.77 (0.024 sec)\n",
      "Step 52050: loss = 0.0475; FVE =  0.76 (0.023 sec)\n",
      "Step 52100: loss = 0.0457; FVE =  0.77 (0.020 sec)\n",
      "Step 52150: loss = 0.0434; FVE =  0.78 (0.021 sec)\n",
      "Step 52200: loss = 0.0424; FVE =  0.79 (0.022 sec)\n",
      "Step 52250: loss = 0.0419; FVE =  0.79 (0.023 sec)\n",
      "Step 52300: loss = 0.0397; FVE =  0.80 (0.024 sec)\n",
      "Step 52350: loss = 0.0474; FVE =  0.76 (0.029 sec)\n",
      "Step 52400: loss = 0.0453; FVE =  0.77 (0.024 sec)\n",
      "Step 52450: loss = 0.0439; FVE =  0.78 (0.022 sec)\n",
      "Step 52500: loss = 0.0446; FVE =  0.78 (0.032 sec)\n",
      "Step 52550: loss = 0.0408; FVE =  0.80 (0.025 sec)\n",
      "Step 52600: loss = 0.0457; FVE =  0.77 (0.027 sec)\n",
      "Step 52650: loss = 0.0424; FVE =  0.79 (0.023 sec)\n",
      "Step 52700: loss = 0.0434; FVE =  0.78 (0.022 sec)\n",
      "Step 52750: loss = 0.0492; FVE =  0.75 (0.020 sec)\n",
      "Step 52800: loss = 0.0442; FVE =  0.78 (0.023 sec)\n",
      "Step 52850: loss = 0.0474; FVE =  0.76 (0.020 sec)\n",
      "Step 52900: loss = 0.0431; FVE =  0.79 (0.026 sec)\n",
      "Step 52950: loss = 0.0420; FVE =  0.79 (0.021 sec)\n",
      "Step 53000: loss = 0.0421; FVE =  0.79 (0.022 sec)\n",
      "Step 53050: loss = 0.0487; FVE =  0.76 (0.019 sec)\n",
      "Step 53100: loss = 0.0429; FVE =  0.79 (0.039 sec)\n",
      "Step 53150: loss = 0.0467; FVE =  0.77 (0.032 sec)\n",
      "Step 53200: loss = 0.0415; FVE =  0.79 (0.022 sec)\n",
      "Step 53250: loss = 0.0430; FVE =  0.79 (0.027 sec)\n",
      "Step 53300: loss = 0.0443; FVE =  0.78 (0.023 sec)\n",
      "Step 53350: loss = 0.0423; FVE =  0.79 (0.026 sec)\n",
      "Step 53400: loss = 0.0477; FVE =  0.76 (0.025 sec)\n",
      "Step 53450: loss = 0.0443; FVE =  0.78 (0.025 sec)\n",
      "Step 53500: loss = 0.0394; FVE =  0.80 (0.025 sec)\n",
      "Step 53550: loss = 0.0454; FVE =  0.77 (0.027 sec)\n",
      "Step 53600: loss = 0.0449; FVE =  0.78 (0.022 sec)\n",
      "Step 53650: loss = 0.0415; FVE =  0.79 (0.021 sec)\n",
      "Step 53700: loss = 0.0451; FVE =  0.78 (0.034 sec)\n",
      "Step 53750: loss = 0.0448; FVE =  0.78 (0.024 sec)\n",
      "Step 53800: loss = 0.0416; FVE =  0.79 (0.021 sec)\n",
      "Step 53850: loss = 0.0471; FVE =  0.77 (0.023 sec)\n",
      "Step 53900: loss = 0.0453; FVE =  0.77 (0.024 sec)\n",
      "Step 53950: loss = 0.0431; FVE =  0.79 (0.025 sec)\n",
      "Step 54000: loss = 0.0426; FVE =  0.79 (0.023 sec)\n",
      "Step 54050: loss = 0.0470; FVE =  0.77 (0.020 sec)\n",
      "Step 54100: loss = 0.0466; FVE =  0.77 (0.021 sec)\n",
      "Step 54150: loss = 0.0471; FVE =  0.77 (0.027 sec)\n",
      "Step 54200: loss = 0.0448; FVE =  0.78 (0.022 sec)\n",
      "Step 54250: loss = 0.0440; FVE =  0.78 (0.026 sec)\n",
      "Step 54300: loss = 0.0438; FVE =  0.78 (0.032 sec)\n",
      "Step 54350: loss = 0.0446; FVE =  0.78 (0.040 sec)\n",
      "Step 54400: loss = 0.0419; FVE =  0.79 (0.022 sec)\n",
      "Step 54450: loss = 0.0412; FVE =  0.79 (0.020 sec)\n",
      "Step 54500: loss = 0.0448; FVE =  0.78 (0.024 sec)\n",
      "Step 54550: loss = 0.0432; FVE =  0.78 (0.019 sec)\n",
      "Step 54600: loss = 0.0406; FVE =  0.80 (0.020 sec)\n",
      "Step 54650: loss = 0.0424; FVE =  0.79 (0.040 sec)\n",
      "Step 54700: loss = 0.0442; FVE =  0.78 (0.020 sec)\n",
      "Step 54750: loss = 0.0437; FVE =  0.78 (0.023 sec)\n",
      "Step 54800: loss = 0.0439; FVE =  0.78 (0.022 sec)\n",
      "Step 54850: loss = 0.0449; FVE =  0.78 (0.024 sec)\n",
      "Step 54900: loss = 0.0411; FVE =  0.80 (0.038 sec)\n",
      "Step 54950: loss = 0.0432; FVE =  0.78 (0.041 sec)\n",
      "Step 55000: loss = 0.0389; FVE =  0.81 (0.024 sec)\n",
      "Step 55050: loss = 0.0434; FVE =  0.78 (0.023 sec)\n",
      "Step 55100: loss = 0.0467; FVE =  0.77 (0.020 sec)\n",
      "Step 55150: loss = 0.0405; FVE =  0.80 (0.022 sec)\n",
      "Step 55200: loss = 0.0445; FVE =  0.78 (0.021 sec)\n",
      "Step 55250: loss = 0.0439; FVE =  0.78 (0.027 sec)\n",
      "Step 55300: loss = 0.0429; FVE =  0.79 (0.022 sec)\n",
      "Step 55350: loss = 0.0426; FVE =  0.79 (0.027 sec)\n",
      "Step 55400: loss = 0.0419; FVE =  0.79 (0.021 sec)\n",
      "Step 55450: loss = 0.0426; FVE =  0.79 (0.022 sec)\n",
      "Step 55500: loss = 0.0437; FVE =  0.78 (0.023 sec)\n",
      "Step 55550: loss = 0.0402; FVE =  0.80 (0.037 sec)\n",
      "Step 55600: loss = 0.0429; FVE =  0.79 (0.020 sec)\n",
      "Step 55650: loss = 0.0438; FVE =  0.78 (0.024 sec)\n",
      "Step 55700: loss = 0.0402; FVE =  0.80 (0.021 sec)\n",
      "Step 55750: loss = 0.0435; FVE =  0.78 (0.020 sec)\n",
      "Step 55800: loss = 0.0451; FVE =  0.78 (0.025 sec)\n",
      "Step 55850: loss = 0.0451; FVE =  0.78 (0.021 sec)\n",
      "Step 55900: loss = 0.0444; FVE =  0.78 (0.027 sec)\n",
      "Step 55950: loss = 0.0410; FVE =  0.80 (0.024 sec)\n",
      "Step 56000: loss = 0.0415; FVE =  0.79 (0.025 sec)\n",
      "Step 56050: loss = 0.0420; FVE =  0.79 (0.021 sec)\n",
      "Step 56100: loss = 0.0468; FVE =  0.77 (0.022 sec)\n",
      "Step 56150: loss = 0.0452; FVE =  0.77 (0.041 sec)\n",
      "Step 56200: loss = 0.0427; FVE =  0.79 (0.026 sec)\n",
      "Step 56250: loss = 0.0432; FVE =  0.78 (0.021 sec)\n",
      "Step 56300: loss = 0.0427; FVE =  0.79 (0.026 sec)\n",
      "Step 56350: loss = 0.0415; FVE =  0.79 (0.023 sec)\n",
      "Step 56400: loss = 0.0407; FVE =  0.80 (0.027 sec)\n",
      "Step 56450: loss = 0.0415; FVE =  0.79 (0.027 sec)\n",
      "Step 56500: loss = 0.0400; FVE =  0.80 (0.023 sec)\n",
      "Step 56550: loss = 0.0424; FVE =  0.79 (0.021 sec)\n",
      "Step 56600: loss = 0.0420; FVE =  0.79 (0.020 sec)\n",
      "Step 56650: loss = 0.0465; FVE =  0.77 (0.028 sec)\n",
      "Step 56700: loss = 0.0449; FVE =  0.78 (0.025 sec)\n",
      "Step 56750: loss = 0.0440; FVE =  0.78 (0.037 sec)\n",
      "Step 56800: loss = 0.0440; FVE =  0.78 (0.022 sec)\n",
      "Step 56850: loss = 0.0377; FVE =  0.81 (0.024 sec)\n",
      "Step 56900: loss = 0.0440; FVE =  0.78 (0.026 sec)\n",
      "Step 56950: loss = 0.0409; FVE =  0.80 (0.025 sec)\n",
      "Step 57000: loss = 0.0427; FVE =  0.79 (0.022 sec)\n",
      "Step 57050: loss = 0.0364; FVE =  0.82 (0.021 sec)\n",
      "Step 57100: loss = 0.0428; FVE =  0.79 (0.026 sec)\n",
      "Step 57150: loss = 0.0421; FVE =  0.79 (0.025 sec)\n",
      "Step 57200: loss = 0.0415; FVE =  0.79 (0.021 sec)\n",
      "Step 57250: loss = 0.0414; FVE =  0.79 (0.024 sec)\n",
      "Step 57300: loss = 0.0436; FVE =  0.78 (0.021 sec)\n",
      "Step 57350: loss = 0.0444; FVE =  0.78 (0.034 sec)\n",
      "Step 57400: loss = 0.0404; FVE =  0.80 (0.022 sec)\n",
      "Step 57450: loss = 0.0434; FVE =  0.78 (0.022 sec)\n",
      "Step 57500: loss = 0.0435; FVE =  0.78 (0.024 sec)\n",
      "Step 57550: loss = 0.0429; FVE =  0.79 (0.022 sec)\n",
      "Step 57600: loss = 0.0397; FVE =  0.80 (0.020 sec)\n",
      "Step 57650: loss = 0.0400; FVE =  0.80 (0.027 sec)\n",
      "Step 57700: loss = 0.0419; FVE =  0.79 (0.021 sec)\n",
      "Step 57750: loss = 0.0438; FVE =  0.78 (0.025 sec)\n",
      "Step 57800: loss = 0.0462; FVE =  0.77 (0.021 sec)\n",
      "Step 57850: loss = 0.0422; FVE =  0.79 (0.021 sec)\n",
      "Step 57900: loss = 0.0400; FVE =  0.80 (0.024 sec)\n",
      "Step 57950: loss = 0.0425; FVE =  0.79 (0.036 sec)\n",
      "Step 58000: loss = 0.0377; FVE =  0.81 (0.026 sec)\n",
      "Step 58050: loss = 0.0385; FVE =  0.81 (0.023 sec)\n",
      "Step 58100: loss = 0.0433; FVE =  0.78 (0.022 sec)\n",
      "Step 58150: loss = 0.0405; FVE =  0.80 (0.024 sec)\n",
      "Step 58200: loss = 0.0430; FVE =  0.79 (0.025 sec)\n",
      "Step 58250: loss = 0.0408; FVE =  0.80 (0.024 sec)\n",
      "Step 58300: loss = 0.0420; FVE =  0.79 (0.026 sec)\n",
      "Step 58350: loss = 0.0386; FVE =  0.81 (0.021 sec)\n",
      "Step 58400: loss = 0.0410; FVE =  0.80 (0.022 sec)\n",
      "Step 58450: loss = 0.0429; FVE =  0.79 (0.031 sec)\n",
      "Step 58500: loss = 0.0411; FVE =  0.80 (0.021 sec)\n",
      "Step 58550: loss = 0.0437; FVE =  0.78 (0.035 sec)\n",
      "Step 58600: loss = 0.0406; FVE =  0.80 (0.021 sec)\n",
      "Step 58650: loss = 0.0447; FVE =  0.78 (0.021 sec)\n",
      "Step 58700: loss = 0.0399; FVE =  0.80 (0.024 sec)\n",
      "Step 58750: loss = 0.0413; FVE =  0.79 (0.026 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 58800: loss = 0.0385; FVE =  0.81 (0.025 sec)\n",
      "Step 58850: loss = 0.0375; FVE =  0.81 (0.024 sec)\n",
      "Step 58900: loss = 0.0445; FVE =  0.78 (0.032 sec)\n",
      "Step 58950: loss = 0.0444; FVE =  0.78 (0.024 sec)\n",
      "Step 59000: loss = 0.0378; FVE =  0.81 (0.023 sec)\n",
      "Step 59050: loss = 0.0411; FVE =  0.80 (0.021 sec)\n",
      "Step 59100: loss = 0.0431; FVE =  0.79 (0.021 sec)\n",
      "Step 59150: loss = 0.0417; FVE =  0.79 (0.038 sec)\n",
      "Step 59200: loss = 0.0445; FVE =  0.78 (0.037 sec)\n",
      "Step 59250: loss = 0.0451; FVE =  0.78 (0.021 sec)\n",
      "Step 59300: loss = 0.0417; FVE =  0.79 (0.024 sec)\n",
      "Step 59350: loss = 0.0411; FVE =  0.80 (0.020 sec)\n",
      "Step 59400: loss = 0.0451; FVE =  0.78 (0.023 sec)\n",
      "Step 59450: loss = 0.0427; FVE =  0.79 (0.022 sec)\n",
      "Step 59500: loss = 0.0417; FVE =  0.79 (0.019 sec)\n",
      "Step 59550: loss = 0.0425; FVE =  0.79 (0.034 sec)\n",
      "Step 59600: loss = 0.0398; FVE =  0.80 (0.024 sec)\n",
      "Step 59650: loss = 0.0413; FVE =  0.79 (0.023 sec)\n",
      "Step 59700: loss = 0.0413; FVE =  0.79 (0.024 sec)\n",
      "Step 59750: loss = 0.0415; FVE =  0.79 (0.031 sec)\n",
      "Step 59800: loss = 0.0407; FVE =  0.80 (0.052 sec)\n",
      "Step 59850: loss = 0.0426; FVE =  0.79 (0.025 sec)\n",
      "Step 59900: loss = 0.0435; FVE =  0.78 (0.058 sec)\n",
      "Step 59950: loss = 0.0442; FVE =  0.78 (0.036 sec)\n",
      "Final results\n",
      "Best Performance: \n",
      "r = 0.625 +- 0.033;  squared (loss) = 0.0968;  FVE = 0.515\n",
      "Evaluation Variance is:\n",
      "0.1966469344714537\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ola-sammy/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "  lossbaseline, lossbaselineneuron  = baseline_error()\n",
    "  run_training(lossbaseline, lossbaselineneuron,dataset = data)\n",
    "\n",
    "# run main\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run(main = main, argv=[sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
